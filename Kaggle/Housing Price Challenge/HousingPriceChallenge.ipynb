{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path):\n",
    "    data=pd.read_csv(path)\n",
    "    return data\n",
    "trainingData=readData('Train/train.csv')\n",
    "testingData=readData('Test/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping Columns\n",
    "def dropColumns(df):\n",
    "    cols_to_drop=['Id','MiscFeature','PoolQC','Fence','FireplaceQu','Alley']\n",
    "    df.drop(columns=cols_to_drop,inplace=True)\n",
    "    return df\n",
    "\n",
    "## Handling Missing Data\n",
    "def handleMissingData(df):\n",
    "    cols=df.columns\n",
    "    for col in cols:\n",
    "        if df[col].isnull().any():\n",
    "            if df[col].dtype==np.dtype('object'):\n",
    "                df[col]=df[col].fillna(df[col].mode().iloc[[0]][0])\n",
    "            elif df[col].dtype==np.int64 or df[col].dtype==np.float64:\n",
    "                df[col]=df[col].fillna(df[col].mean())\n",
    "    return df\n",
    "\n",
    "trainingData=dropColumns(trainingData)\n",
    "trainingData=handleMissingData(trainingData)\n",
    "testingData=dropColumns(testingData)\n",
    "testingData=handleMissingData(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "trainingData=oneHotEncode(trainingData,trainingData.columns)\n",
    "testingData=oneHotEncode(testingData,testingData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=trainingData['SalePrice']\n",
    "def getCommonColumns(df1,df2):\n",
    "    return list(set(df1.columns).intersection(set(df2.columns)))\n",
    "\n",
    "common_columns=getCommonColumns(trainingData,testingData)\n",
    " \n",
    "trainingData=trainingData[common_columns]\n",
    "testingData=testingData[common_columns]\n",
    "trainingData=pd.concat([trainingData,target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT=trainingData.values[:,:-1]\n",
    "YT=trainingData.values[:,-1]\n",
    "\n",
    "Xt=testingData.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (None, 100)               25500     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 53,101\n",
      "Trainable params: 53,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=models.Sequential()\n",
    "model.add(Dense(100,kernel_initializer='normal',activation='relu',input_shape=(254,)))\n",
    "model.add(Dense(50,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(50,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(50,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(50,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['mean_absolute_error'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'CheckPoints/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "1168/1168 [==============================] - 1s 822us/step - loss: 168184.4858 - mean_absolute_error: 168184.5000 - val_loss: 91603.6997 - val_mean_absolute_error: 91603.6953\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 91603.69970, saving model to CheckPoints/Weights-001--91603.69970.hdf5\n",
      "Epoch 2/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 58112.0683 - mean_absolute_error: 58112.0820 - val_loss: 47637.8995 - val_mean_absolute_error: 47637.9023\n",
      "\n",
      "Epoch 00002: val_loss improved from 91603.69970 to 47637.89951, saving model to CheckPoints/Weights-002--47637.89951.hdf5\n",
      "Epoch 3/1000\n",
      "1168/1168 [==============================] - 0s 148us/step - loss: 47944.2362 - mean_absolute_error: 47944.2422 - val_loss: 45248.4514 - val_mean_absolute_error: 45248.4531\n",
      "\n",
      "Epoch 00003: val_loss improved from 47637.89951 to 45248.45141, saving model to CheckPoints/Weights-003--45248.45141.hdf5\n",
      "Epoch 4/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 42694.4455 - mean_absolute_error: 42694.4531 - val_loss: 40168.8321 - val_mean_absolute_error: 40168.8281\n",
      "\n",
      "Epoch 00004: val_loss improved from 45248.45141 to 40168.83208, saving model to CheckPoints/Weights-004--40168.83208.hdf5\n",
      "Epoch 5/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 37751.6368 - mean_absolute_error: 37751.6367 - val_loss: 36832.2115 - val_mean_absolute_error: 36832.2109\n",
      "\n",
      "Epoch 00005: val_loss improved from 40168.83208 to 36832.21153, saving model to CheckPoints/Weights-005--36832.21153.hdf5\n",
      "Epoch 6/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 33681.1051 - mean_absolute_error: 33681.1055 - val_loss: 34014.0153 - val_mean_absolute_error: 34014.0156\n",
      "\n",
      "Epoch 00006: val_loss improved from 36832.21153 to 34014.01533, saving model to CheckPoints/Weights-006--34014.01533.hdf5\n",
      "Epoch 7/1000\n",
      "1168/1168 [==============================] - 0s 149us/step - loss: 30782.7036 - mean_absolute_error: 30782.7051 - val_loss: 32112.2763 - val_mean_absolute_error: 32112.2773\n",
      "\n",
      "Epoch 00007: val_loss improved from 34014.01533 to 32112.27630, saving model to CheckPoints/Weights-007--32112.27630.hdf5\n",
      "Epoch 8/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 29676.9384 - mean_absolute_error: 29676.9375 - val_loss: 31199.8064 - val_mean_absolute_error: 31199.8047\n",
      "\n",
      "Epoch 00008: val_loss improved from 32112.27630 to 31199.80640, saving model to CheckPoints/Weights-008--31199.80640.hdf5\n",
      "Epoch 9/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 28418.0631 - mean_absolute_error: 28418.0625 - val_loss: 30850.3452 - val_mean_absolute_error: 30850.3457\n",
      "\n",
      "Epoch 00009: val_loss improved from 31199.80640 to 30850.34525, saving model to CheckPoints/Weights-009--30850.34525.hdf5\n",
      "Epoch 10/1000\n",
      "1168/1168 [==============================] - 0s 145us/step - loss: 27366.4887 - mean_absolute_error: 27366.4883 - val_loss: 30371.7554 - val_mean_absolute_error: 30371.7578\n",
      "\n",
      "Epoch 00010: val_loss improved from 30850.34525 to 30371.75535, saving model to CheckPoints/Weights-010--30371.75535.hdf5\n",
      "Epoch 11/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 26673.4943 - mean_absolute_error: 26673.4980 - val_loss: 31429.9754 - val_mean_absolute_error: 31429.9766\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 30371.75535\n",
      "Epoch 12/1000\n",
      "1168/1168 [==============================] - 0s 146us/step - loss: 27373.1907 - mean_absolute_error: 27373.1895 - val_loss: 29979.5403 - val_mean_absolute_error: 29979.5371\n",
      "\n",
      "Epoch 00012: val_loss improved from 30371.75535 to 29979.54029, saving model to CheckPoints/Weights-012--29979.54029.hdf5\n",
      "Epoch 13/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 27346.0360 - mean_absolute_error: 27346.0371 - val_loss: 31347.7952 - val_mean_absolute_error: 31347.7949\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 29979.54029\n",
      "Epoch 14/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 26776.4667 - mean_absolute_error: 26776.4707 - val_loss: 29544.4428 - val_mean_absolute_error: 29544.4453\n",
      "\n",
      "Epoch 00014: val_loss improved from 29979.54029 to 29544.44280, saving model to CheckPoints/Weights-014--29544.44280.hdf5\n",
      "Epoch 15/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 26214.7594 - mean_absolute_error: 26214.7559 - val_loss: 30793.8177 - val_mean_absolute_error: 30793.8184\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 29544.44280\n",
      "Epoch 16/1000\n",
      "1168/1168 [==============================] - 0s 148us/step - loss: 25935.9150 - mean_absolute_error: 25935.9121 - val_loss: 29429.9861 - val_mean_absolute_error: 29429.9863\n",
      "\n",
      "Epoch 00016: val_loss improved from 29544.44280 to 29429.98614, saving model to CheckPoints/Weights-016--29429.98614.hdf5\n",
      "Epoch 17/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 25734.2817 - mean_absolute_error: 25734.2812 - val_loss: 29111.0304 - val_mean_absolute_error: 29111.0312\n",
      "\n",
      "Epoch 00017: val_loss improved from 29429.98614 to 29111.03039, saving model to CheckPoints/Weights-017--29111.03039.hdf5\n",
      "Epoch 18/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 25886.1977 - mean_absolute_error: 25886.1973 - val_loss: 30799.0067 - val_mean_absolute_error: 30799.0078\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 29111.03039\n",
      "Epoch 19/1000\n",
      "1168/1168 [==============================] - 0s 165us/step - loss: 25428.2008 - mean_absolute_error: 25428.1992 - val_loss: 30637.0070 - val_mean_absolute_error: 30637.0098\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 29111.03039\n",
      "Epoch 20/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 25210.8696 - mean_absolute_error: 25210.8691 - val_loss: 29140.8838 - val_mean_absolute_error: 29140.8828\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 29111.03039\n",
      "Epoch 21/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 24929.4457 - mean_absolute_error: 24929.4395 - val_loss: 28766.6520 - val_mean_absolute_error: 28766.6504\n",
      "\n",
      "Epoch 00021: val_loss improved from 29111.03039 to 28766.65197, saving model to CheckPoints/Weights-021--28766.65197.hdf5\n",
      "Epoch 22/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 25021.0410 - mean_absolute_error: 25021.0410 - val_loss: 29593.5694 - val_mean_absolute_error: 29593.5684\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 28766.65197\n",
      "Epoch 23/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 25117.2903 - mean_absolute_error: 25117.2891 - val_loss: 28380.0104 - val_mean_absolute_error: 28380.0098\n",
      "\n",
      "Epoch 00023: val_loss improved from 28766.65197 to 28380.01038, saving model to CheckPoints/Weights-023--28380.01038.hdf5\n",
      "Epoch 24/1000\n",
      "1168/1168 [==============================] - 0s 131us/step - loss: 24630.2588 - mean_absolute_error: 24630.2617 - val_loss: 29129.3725 - val_mean_absolute_error: 29129.3730\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 28380.01038\n",
      "Epoch 25/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 24966.3617 - mean_absolute_error: 24966.3613 - val_loss: 30572.8557 - val_mean_absolute_error: 30572.8555\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 28380.01038\n",
      "Epoch 26/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 25079.7306 - mean_absolute_error: 25079.7305 - val_loss: 28314.4883 - val_mean_absolute_error: 28314.4883\n",
      "\n",
      "Epoch 00026: val_loss improved from 28380.01038 to 28314.48833, saving model to CheckPoints/Weights-026--28314.48833.hdf5\n",
      "Epoch 27/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 24219.4794 - mean_absolute_error: 24219.4805 - val_loss: 28474.8923 - val_mean_absolute_error: 28474.8945\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 28314.48833\n",
      "Epoch 28/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 23878.2522 - mean_absolute_error: 23878.2500 - val_loss: 28862.2678 - val_mean_absolute_error: 28862.2676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 28314.48833\n",
      "Epoch 29/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 24049.8110 - mean_absolute_error: 24049.8066 - val_loss: 28560.6077 - val_mean_absolute_error: 28560.6055\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 28314.48833\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 139us/step - loss: 23865.3920 - mean_absolute_error: 23865.3867 - val_loss: 28154.0855 - val_mean_absolute_error: 28154.0859\n",
      "\n",
      "Epoch 00030: val_loss improved from 28314.48833 to 28154.08551, saving model to CheckPoints/Weights-030--28154.08551.hdf5\n",
      "Epoch 31/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 23910.9587 - mean_absolute_error: 23910.9590 - val_loss: 30187.8565 - val_mean_absolute_error: 30187.8555\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 28154.08551\n",
      "Epoch 32/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 24615.3316 - mean_absolute_error: 24615.3281 - val_loss: 28687.3889 - val_mean_absolute_error: 28687.3906\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 28154.08551\n",
      "Epoch 33/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 23755.5364 - mean_absolute_error: 23755.5352 - val_loss: 28400.5714 - val_mean_absolute_error: 28400.5723\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 28154.08551\n",
      "Epoch 34/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 24155.1177 - mean_absolute_error: 24155.1172 - val_loss: 27732.2481 - val_mean_absolute_error: 27732.2480\n",
      "\n",
      "Epoch 00034: val_loss improved from 28154.08551 to 27732.24813, saving model to CheckPoints/Weights-034--27732.24813.hdf5\n",
      "Epoch 35/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 24489.1070 - mean_absolute_error: 24489.1035 - val_loss: 27911.0108 - val_mean_absolute_error: 27911.0098\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 27732.24813\n",
      "Epoch 36/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 23841.7414 - mean_absolute_error: 23841.7422 - val_loss: 28519.5463 - val_mean_absolute_error: 28519.5449\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 27732.24813\n",
      "Epoch 37/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 23787.9732 - mean_absolute_error: 23787.9746 - val_loss: 28208.2242 - val_mean_absolute_error: 28208.2227\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 27732.24813\n",
      "Epoch 38/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 24612.8701 - mean_absolute_error: 24612.8691 - val_loss: 28643.8965 - val_mean_absolute_error: 28643.8965\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 27732.24813\n",
      "Epoch 39/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 23302.8580 - mean_absolute_error: 23302.8555 - val_loss: 27920.0140 - val_mean_absolute_error: 27920.0176\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 27732.24813\n",
      "Epoch 40/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 23020.8672 - mean_absolute_error: 23020.8672 - val_loss: 27578.8507 - val_mean_absolute_error: 27578.8535\n",
      "\n",
      "Epoch 00040: val_loss improved from 27732.24813 to 27578.85068, saving model to CheckPoints/Weights-040--27578.85068.hdf5\n",
      "Epoch 41/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 23837.5453 - mean_absolute_error: 23837.5449 - val_loss: 29252.2192 - val_mean_absolute_error: 29252.2188\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 27578.85068\n",
      "Epoch 42/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 23290.2630 - mean_absolute_error: 23290.2617 - val_loss: 28592.7422 - val_mean_absolute_error: 28592.7402\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 27578.85068\n",
      "Epoch 43/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 23733.4761 - mean_absolute_error: 23733.4785 - val_loss: 28911.8556 - val_mean_absolute_error: 28911.8555\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 27578.85068\n",
      "Epoch 44/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 23764.4982 - mean_absolute_error: 23764.4961 - val_loss: 27404.9873 - val_mean_absolute_error: 27404.9863\n",
      "\n",
      "Epoch 00044: val_loss improved from 27578.85068 to 27404.98734, saving model to CheckPoints/Weights-044--27404.98734.hdf5\n",
      "Epoch 45/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 23084.7680 - mean_absolute_error: 23084.7695 - val_loss: 27360.4046 - val_mean_absolute_error: 27360.4043\n",
      "\n",
      "Epoch 00045: val_loss improved from 27404.98734 to 27360.40464, saving model to CheckPoints/Weights-045--27360.40464.hdf5\n",
      "Epoch 46/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 23142.8323 - mean_absolute_error: 23142.8340 - val_loss: 27992.1285 - val_mean_absolute_error: 27992.1270\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 27360.40464\n",
      "Epoch 47/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 23015.7395 - mean_absolute_error: 23015.7363 - val_loss: 27335.8695 - val_mean_absolute_error: 27335.8672\n",
      "\n",
      "Epoch 00047: val_loss improved from 27360.40464 to 27335.86952, saving model to CheckPoints/Weights-047--27335.86952.hdf5\n",
      "Epoch 48/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 23538.3444 - mean_absolute_error: 23538.3418 - val_loss: 27585.5587 - val_mean_absolute_error: 27585.5566\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 27335.86952\n",
      "Epoch 49/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 22780.0658 - mean_absolute_error: 22780.0625 - val_loss: 27820.2282 - val_mean_absolute_error: 27820.2285\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 27335.86952\n",
      "Epoch 50/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 22834.5928 - mean_absolute_error: 22834.5898 - val_loss: 28228.3809 - val_mean_absolute_error: 28228.3828\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 27335.86952\n",
      "Epoch 51/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 22431.3455 - mean_absolute_error: 22431.3477 - val_loss: 27260.8965 - val_mean_absolute_error: 27260.8965\n",
      "\n",
      "Epoch 00051: val_loss improved from 27335.86952 to 27260.89646, saving model to CheckPoints/Weights-051--27260.89646.hdf5\n",
      "Epoch 52/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 23330.0638 - mean_absolute_error: 23330.0625 - val_loss: 27097.0215 - val_mean_absolute_error: 27097.0215\n",
      "\n",
      "Epoch 00052: val_loss improved from 27260.89646 to 27097.02151, saving model to CheckPoints/Weights-052--27097.02151.hdf5\n",
      "Epoch 53/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 22474.7665 - mean_absolute_error: 22474.7676 - val_loss: 27123.3775 - val_mean_absolute_error: 27123.3789\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 27097.02151\n",
      "Epoch 54/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 23264.8398 - mean_absolute_error: 23264.8379 - val_loss: 27790.8646 - val_mean_absolute_error: 27790.8652\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 27097.02151\n",
      "Epoch 55/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 23044.5651 - mean_absolute_error: 23044.5645 - val_loss: 27261.2869 - val_mean_absolute_error: 27261.2891\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 27097.02151\n",
      "Epoch 56/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 22454.6802 - mean_absolute_error: 22454.6797 - val_loss: 28606.3915 - val_mean_absolute_error: 28606.3945\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 27097.02151\n",
      "Epoch 57/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 23964.4158 - mean_absolute_error: 23964.4180 - val_loss: 26887.9981 - val_mean_absolute_error: 26888.0000\n",
      "\n",
      "Epoch 00057: val_loss improved from 27097.02151 to 26887.99813, saving model to CheckPoints/Weights-057--26887.99813.hdf5\n",
      "Epoch 58/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 23020.2363 - mean_absolute_error: 23020.2422 - val_loss: 27162.0116 - val_mean_absolute_error: 27162.0117\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 26887.99813\n",
      "Epoch 59/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 22435.0281 - mean_absolute_error: 22435.0312 - val_loss: 29476.5433 - val_mean_absolute_error: 29476.5449\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 26887.99813\n",
      "Epoch 60/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 22318.3402 - mean_absolute_error: 22318.3398 - val_loss: 28143.2619 - val_mean_absolute_error: 28143.2617\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 26887.99813\n",
      "Epoch 61/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 22366.8094 - mean_absolute_error: 22366.8125 - val_loss: 27317.8326 - val_mean_absolute_error: 27317.8320\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 26887.99813\n",
      "Epoch 62/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 21980.2582 - mean_absolute_error: 21980.2578 - val_loss: 27960.9302 - val_mean_absolute_error: 27960.9297\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 26887.99813\n",
      "Epoch 63/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 22297.1707 - mean_absolute_error: 22297.1699 - val_loss: 26746.4021 - val_mean_absolute_error: 26746.4023\n",
      "\n",
      "Epoch 00063: val_loss improved from 26887.99813 to 26746.40208, saving model to CheckPoints/Weights-063--26746.40208.hdf5\n",
      "Epoch 64/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 21865.3601 - mean_absolute_error: 21865.3594 - val_loss: 26678.2610 - val_mean_absolute_error: 26678.2598\n",
      "\n",
      "Epoch 00064: val_loss improved from 26746.40208 to 26678.26102, saving model to CheckPoints/Weights-064--26678.26102.hdf5\n",
      "Epoch 65/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 22098.9659 - mean_absolute_error: 22098.9648 - val_loss: 26665.3355 - val_mean_absolute_error: 26665.3340\n",
      "\n",
      "Epoch 00065: val_loss improved from 26678.26102 to 26665.33551, saving model to CheckPoints/Weights-065--26665.33551.hdf5\n",
      "Epoch 66/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 22305.0422 - mean_absolute_error: 22305.0410 - val_loss: 27924.5325 - val_mean_absolute_error: 27924.5332\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 26665.33551\n",
      "Epoch 67/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 21660.6800 - mean_absolute_error: 21660.6738 - val_loss: 27291.4317 - val_mean_absolute_error: 27291.4336\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 26665.33551\n",
      "Epoch 68/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 22124.4362 - mean_absolute_error: 22124.4355 - val_loss: 26955.9851 - val_mean_absolute_error: 26955.9863\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 26665.33551\n",
      "Epoch 69/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 21665.3231 - mean_absolute_error: 21665.3242 - val_loss: 27596.9064 - val_mean_absolute_error: 27596.9082\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 26665.33551\n",
      "Epoch 70/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 22568.7299 - mean_absolute_error: 22568.7285 - val_loss: 26834.3274 - val_mean_absolute_error: 26834.3281\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 26665.33551\n",
      "Epoch 71/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 22102.6858 - mean_absolute_error: 22102.6836 - val_loss: 26730.2250 - val_mean_absolute_error: 26730.2246\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 26665.33551\n",
      "Epoch 72/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 22223.8810 - mean_absolute_error: 22223.8828 - val_loss: 29691.3696 - val_mean_absolute_error: 29691.3691\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 26665.33551\n",
      "Epoch 73/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 22280.0625 - mean_absolute_error: 22280.0605 - val_loss: 26589.4506 - val_mean_absolute_error: 26589.4512\n",
      "\n",
      "Epoch 00073: val_loss improved from 26665.33551 to 26589.45061, saving model to CheckPoints/Weights-073--26589.45061.hdf5\n",
      "Epoch 74/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 21398.3134 - mean_absolute_error: 21398.3105 - val_loss: 26585.4108 - val_mean_absolute_error: 26585.4102\n",
      "\n",
      "Epoch 00074: val_loss improved from 26589.45061 to 26585.41080, saving model to CheckPoints/Weights-074--26585.41080.hdf5\n",
      "Epoch 75/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 21494.6694 - mean_absolute_error: 21494.6699 - val_loss: 26434.8201 - val_mean_absolute_error: 26434.8203\n",
      "\n",
      "Epoch 00075: val_loss improved from 26585.41080 to 26434.82010, saving model to CheckPoints/Weights-075--26434.82010.hdf5\n",
      "Epoch 76/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 21281.5243 - mean_absolute_error: 21281.5293 - val_loss: 28268.4856 - val_mean_absolute_error: 28268.4863\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 26434.82010\n",
      "Epoch 77/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 21853.7270 - mean_absolute_error: 21853.7246 - val_loss: 27295.8500 - val_mean_absolute_error: 27295.8535\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 26434.82010\n",
      "Epoch 78/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 21902.7226 - mean_absolute_error: 21902.7227 - val_loss: 26559.1421 - val_mean_absolute_error: 26559.1445\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 26434.82010\n",
      "Epoch 79/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 21377.4447 - mean_absolute_error: 21377.4473 - val_loss: 27156.8937 - val_mean_absolute_error: 27156.8926\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 26434.82010\n",
      "Epoch 80/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 21798.1562 - mean_absolute_error: 21798.1582 - val_loss: 26184.9555 - val_mean_absolute_error: 26184.9551\n",
      "\n",
      "Epoch 00080: val_loss improved from 26434.82010 to 26184.95548, saving model to CheckPoints/Weights-080--26184.95548.hdf5\n",
      "Epoch 81/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 22003.4886 - mean_absolute_error: 22003.4922 - val_loss: 26512.2822 - val_mean_absolute_error: 26512.2832\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 26184.95548\n",
      "Epoch 82/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 20982.6228 - mean_absolute_error: 20982.6230 - val_loss: 26320.0795 - val_mean_absolute_error: 26320.0781\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 26184.95548\n",
      "Epoch 83/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 21674.6135 - mean_absolute_error: 21674.6152 - val_loss: 28515.9524 - val_mean_absolute_error: 28515.9512\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 26184.95548\n",
      "Epoch 84/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 21206.0727 - mean_absolute_error: 21206.0684 - val_loss: 27122.1180 - val_mean_absolute_error: 27122.1172\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 26184.95548\n",
      "Epoch 85/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 20972.0842 - mean_absolute_error: 20972.0859 - val_loss: 26729.2519 - val_mean_absolute_error: 26729.2520\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 26184.95548\n",
      "Epoch 86/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 20721.8799 - mean_absolute_error: 20721.8770 - val_loss: 27005.0346 - val_mean_absolute_error: 27005.0332\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 26184.95548\n",
      "Epoch 87/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 21466.6111 - mean_absolute_error: 21466.6094 - val_loss: 27526.9263 - val_mean_absolute_error: 27526.9258\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 26184.95548\n",
      "Epoch 88/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 21389.2105 - mean_absolute_error: 21389.2051 - val_loss: 26233.8792 - val_mean_absolute_error: 26233.8789\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 26184.95548\n",
      "Epoch 89/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 21229.5311 - mean_absolute_error: 21229.5332 - val_loss: 27276.3109 - val_mean_absolute_error: 27276.3105\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 26184.95548\n",
      "Epoch 90/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 21884.5717 - mean_absolute_error: 21884.5703 - val_loss: 30041.7775 - val_mean_absolute_error: 30041.7773\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 26184.95548\n",
      "Epoch 91/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 20516.2402 - mean_absolute_error: 20516.2422 - val_loss: 26678.7596 - val_mean_absolute_error: 26678.7598\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 26184.95548\n",
      "Epoch 92/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 20663.7646 - mean_absolute_error: 20663.7656 - val_loss: 25950.3670 - val_mean_absolute_error: 25950.3672\n",
      "\n",
      "Epoch 00092: val_loss improved from 26184.95548 to 25950.36697, saving model to CheckPoints/Weights-092--25950.36697.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 20680.8570 - mean_absolute_error: 20680.8633 - val_loss: 26680.4654 - val_mean_absolute_error: 26680.4648\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 25950.36697\n",
      "Epoch 94/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 20509.3704 - mean_absolute_error: 20509.3711 - val_loss: 29567.2244 - val_mean_absolute_error: 29567.2266\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 25950.36697\n",
      "Epoch 95/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 20834.9638 - mean_absolute_error: 20834.9648 - val_loss: 26189.8644 - val_mean_absolute_error: 26189.8652\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 25950.36697\n",
      "Epoch 96/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 21066.1959 - mean_absolute_error: 21066.1973 - val_loss: 25885.7997 - val_mean_absolute_error: 25885.7988\n",
      "\n",
      "Epoch 00096: val_loss improved from 25950.36697 to 25885.79966, saving model to CheckPoints/Weights-096--25885.79966.hdf5\n",
      "Epoch 97/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 20402.1522 - mean_absolute_error: 20402.1523 - val_loss: 28128.0144 - val_mean_absolute_error: 28128.0156\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 25885.79966\n",
      "Epoch 98/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 20874.9671 - mean_absolute_error: 20874.9688 - val_loss: 25745.4079 - val_mean_absolute_error: 25745.4082\n",
      "\n",
      "Epoch 00098: val_loss improved from 25885.79966 to 25745.40786, saving model to CheckPoints/Weights-098--25745.40786.hdf5\n",
      "Epoch 99/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 20391.6129 - mean_absolute_error: 20391.6133 - val_loss: 25758.3427 - val_mean_absolute_error: 25758.3457\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 25745.40786\n",
      "Epoch 100/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 20393.0387 - mean_absolute_error: 20393.0371 - val_loss: 25622.6794 - val_mean_absolute_error: 25622.6816\n",
      "\n",
      "Epoch 00100: val_loss improved from 25745.40786 to 25622.67942, saving model to CheckPoints/Weights-100--25622.67942.hdf5\n",
      "Epoch 101/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 19931.2992 - mean_absolute_error: 19931.3008 - val_loss: 25668.2883 - val_mean_absolute_error: 25668.2871\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 25622.67942\n",
      "Epoch 102/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 19747.3667 - mean_absolute_error: 19747.3672 - val_loss: 25900.8934 - val_mean_absolute_error: 25900.8926\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 25622.67942\n",
      "Epoch 103/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 19805.4167 - mean_absolute_error: 19805.4160 - val_loss: 25280.2702 - val_mean_absolute_error: 25280.2715\n",
      "\n",
      "Epoch 00103: val_loss improved from 25622.67942 to 25280.27017, saving model to CheckPoints/Weights-103--25280.27017.hdf5\n",
      "Epoch 104/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 19609.4656 - mean_absolute_error: 19609.4648 - val_loss: 26177.2546 - val_mean_absolute_error: 26177.2539\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 25280.27017\n",
      "Epoch 105/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 19823.3991 - mean_absolute_error: 19823.3965 - val_loss: 25678.6147 - val_mean_absolute_error: 25678.6152\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 25280.27017\n",
      "Epoch 106/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 19728.2294 - mean_absolute_error: 19728.2285 - val_loss: 25481.3113 - val_mean_absolute_error: 25481.3125\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 25280.27017\n",
      "Epoch 107/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 19688.1178 - mean_absolute_error: 19688.1172 - val_loss: 26218.0624 - val_mean_absolute_error: 26218.0625\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 25280.27017\n",
      "Epoch 108/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 19559.3263 - mean_absolute_error: 19559.3242 - val_loss: 27645.1708 - val_mean_absolute_error: 27645.1699\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 25280.27017\n",
      "Epoch 109/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 20574.4664 - mean_absolute_error: 20574.4688 - val_loss: 26365.7099 - val_mean_absolute_error: 26365.7109\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 25280.27017\n",
      "Epoch 110/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 19324.8489 - mean_absolute_error: 19324.8477 - val_loss: 25538.8369 - val_mean_absolute_error: 25538.8379\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 25280.27017\n",
      "Epoch 111/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 19233.6638 - mean_absolute_error: 19233.6641 - val_loss: 25214.4991 - val_mean_absolute_error: 25214.5000\n",
      "\n",
      "Epoch 00111: val_loss improved from 25280.27017 to 25214.49914, saving model to CheckPoints/Weights-111--25214.49914.hdf5\n",
      "Epoch 112/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 19868.5723 - mean_absolute_error: 19868.5723 - val_loss: 27828.9186 - val_mean_absolute_error: 27828.9180\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 25214.49914\n",
      "Epoch 113/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 21070.9152 - mean_absolute_error: 21070.9160 - val_loss: 29201.8937 - val_mean_absolute_error: 29201.8945\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 25214.49914\n",
      "Epoch 114/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 19871.3839 - mean_absolute_error: 19871.3848 - val_loss: 26869.3938 - val_mean_absolute_error: 26869.3945\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 25214.49914\n",
      "Epoch 115/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 19618.3376 - mean_absolute_error: 19618.3359 - val_loss: 29044.7177 - val_mean_absolute_error: 29044.7188\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 25214.49914\n",
      "Epoch 116/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 20301.3094 - mean_absolute_error: 20301.3105 - val_loss: 24685.9400 - val_mean_absolute_error: 24685.9375\n",
      "\n",
      "Epoch 00116: val_loss improved from 25214.49914 to 24685.94001, saving model to CheckPoints/Weights-116--24685.94001.hdf5\n",
      "Epoch 117/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 19181.4058 - mean_absolute_error: 19181.4043 - val_loss: 24961.7261 - val_mean_absolute_error: 24961.7266\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 24685.94001\n",
      "Epoch 118/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 19278.1121 - mean_absolute_error: 19278.1113 - val_loss: 24657.8921 - val_mean_absolute_error: 24657.8926\n",
      "\n",
      "Epoch 00118: val_loss improved from 24685.94001 to 24657.89212, saving model to CheckPoints/Weights-118--24657.89212.hdf5\n",
      "Epoch 119/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 18987.7148 - mean_absolute_error: 18987.7148 - val_loss: 26145.5023 - val_mean_absolute_error: 26145.5020\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 24657.89212\n",
      "Epoch 120/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 18862.0970 - mean_absolute_error: 18862.0996 - val_loss: 26246.9356 - val_mean_absolute_error: 26246.9375\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 24657.89212\n",
      "Epoch 121/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 18739.9244 - mean_absolute_error: 18739.9238 - val_loss: 24229.4296 - val_mean_absolute_error: 24229.4277\n",
      "\n",
      "Epoch 00121: val_loss improved from 24657.89212 to 24229.42963, saving model to CheckPoints/Weights-121--24229.42963.hdf5\n",
      "Epoch 122/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 19576.9933 - mean_absolute_error: 19576.9922 - val_loss: 24837.2992 - val_mean_absolute_error: 24837.2988\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 24229.42963\n",
      "Epoch 123/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 19214.5789 - mean_absolute_error: 19214.5781 - val_loss: 24001.7137 - val_mean_absolute_error: 24001.7148\n",
      "\n",
      "Epoch 00123: val_loss improved from 24229.42963 to 24001.71367, saving model to CheckPoints/Weights-123--24001.71367.hdf5\n",
      "Epoch 124/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 18572.6419 - mean_absolute_error: 18572.6406 - val_loss: 23973.3983 - val_mean_absolute_error: 23973.3965\n",
      "\n",
      "Epoch 00124: val_loss improved from 24001.71367 to 23973.39833, saving model to CheckPoints/Weights-124--23973.39833.hdf5\n",
      "Epoch 125/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 18373.3433 - mean_absolute_error: 18373.3438 - val_loss: 24154.6583 - val_mean_absolute_error: 24154.6602\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 23973.39833\n",
      "Epoch 126/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 18235.3992 - mean_absolute_error: 18235.4004 - val_loss: 24732.6120 - val_mean_absolute_error: 24732.6094\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 23973.39833\n",
      "Epoch 127/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 18210.0021 - mean_absolute_error: 18210.0039 - val_loss: 24421.5693 - val_mean_absolute_error: 24421.5703\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 23973.39833\n",
      "Epoch 128/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 18105.7588 - mean_absolute_error: 18105.7559 - val_loss: 24778.3135 - val_mean_absolute_error: 24778.3125\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 23973.39833\n",
      "Epoch 129/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 17871.2561 - mean_absolute_error: 17871.2559 - val_loss: 23964.9661 - val_mean_absolute_error: 23964.9668\n",
      "\n",
      "Epoch 00129: val_loss improved from 23973.39833 to 23964.96613, saving model to CheckPoints/Weights-129--23964.96613.hdf5\n",
      "Epoch 130/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 18502.0353 - mean_absolute_error: 18502.0352 - val_loss: 23752.1593 - val_mean_absolute_error: 23752.1602\n",
      "\n",
      "Epoch 00130: val_loss improved from 23964.96613 to 23752.15930, saving model to CheckPoints/Weights-130--23752.15930.hdf5\n",
      "Epoch 131/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 20078.1842 - mean_absolute_error: 20078.1875 - val_loss: 24079.4150 - val_mean_absolute_error: 24079.4160\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 23752.15930\n",
      "Epoch 132/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 19759.1996 - mean_absolute_error: 19759.1992 - val_loss: 24508.8875 - val_mean_absolute_error: 24508.8887\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 23752.15930\n",
      "Epoch 133/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 18837.1357 - mean_absolute_error: 18837.1348 - val_loss: 23655.4786 - val_mean_absolute_error: 23655.4785\n",
      "\n",
      "Epoch 00133: val_loss improved from 23752.15930 to 23655.47865, saving model to CheckPoints/Weights-133--23655.47865.hdf5\n",
      "Epoch 134/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 18750.8037 - mean_absolute_error: 18750.8047 - val_loss: 23678.4062 - val_mean_absolute_error: 23678.4082\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 23655.47865\n",
      "Epoch 135/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 18771.5948 - mean_absolute_error: 18771.5918 - val_loss: 24369.2216 - val_mean_absolute_error: 24369.2227\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 23655.47865\n",
      "Epoch 136/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 18664.8672 - mean_absolute_error: 18664.8633 - val_loss: 23982.1392 - val_mean_absolute_error: 23982.1387\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 23655.47865\n",
      "Epoch 137/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17652.6770 - mean_absolute_error: 17652.6738 - val_loss: 24575.7123 - val_mean_absolute_error: 24575.7129\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 23655.47865\n",
      "Epoch 138/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 18160.0641 - mean_absolute_error: 18160.0645 - val_loss: 24317.3855 - val_mean_absolute_error: 24317.3848\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 23655.47865\n",
      "Epoch 139/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 19946.8401 - mean_absolute_error: 19946.8398 - val_loss: 23456.1043 - val_mean_absolute_error: 23456.1035\n",
      "\n",
      "Epoch 00139: val_loss improved from 23655.47865 to 23456.10435, saving model to CheckPoints/Weights-139--23456.10435.hdf5\n",
      "Epoch 140/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 17423.0296 - mean_absolute_error: 17423.0312 - val_loss: 23634.5563 - val_mean_absolute_error: 23634.5566\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 23456.10435\n",
      "Epoch 141/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17553.6703 - mean_absolute_error: 17553.6699 - val_loss: 24362.6083 - val_mean_absolute_error: 24362.6055\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 23456.10435\n",
      "Epoch 142/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 17557.2240 - mean_absolute_error: 17557.2246 - val_loss: 23018.5140 - val_mean_absolute_error: 23018.5137\n",
      "\n",
      "Epoch 00142: val_loss improved from 23456.10435 to 23018.51397, saving model to CheckPoints/Weights-142--23018.51397.hdf5\n",
      "Epoch 143/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 17812.6713 - mean_absolute_error: 17812.6738 - val_loss: 24282.6593 - val_mean_absolute_error: 24282.6602\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 23018.51397\n",
      "Epoch 144/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 17536.6891 - mean_absolute_error: 17536.6875 - val_loss: 22883.6746 - val_mean_absolute_error: 22883.6738\n",
      "\n",
      "Epoch 00144: val_loss improved from 23018.51397 to 22883.67455, saving model to CheckPoints/Weights-144--22883.67455.hdf5\n",
      "Epoch 145/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 17450.4949 - mean_absolute_error: 17450.4941 - val_loss: 23459.5986 - val_mean_absolute_error: 23459.5996\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 22883.67455\n",
      "Epoch 146/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 17179.4788 - mean_absolute_error: 17179.4785 - val_loss: 24646.7483 - val_mean_absolute_error: 24646.7500\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 22883.67455\n",
      "Epoch 147/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 18480.1785 - mean_absolute_error: 18480.1797 - val_loss: 23813.5666 - val_mean_absolute_error: 23813.5664\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 22883.67455\n",
      "Epoch 148/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 18027.4967 - mean_absolute_error: 18027.4961 - val_loss: 22624.7760 - val_mean_absolute_error: 22624.7754\n",
      "\n",
      "Epoch 00148: val_loss improved from 22883.67455 to 22624.77595, saving model to CheckPoints/Weights-148--22624.77595.hdf5\n",
      "Epoch 149/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 17715.2094 - mean_absolute_error: 17715.2090 - val_loss: 23789.9344 - val_mean_absolute_error: 23789.9375\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 22624.77595\n",
      "Epoch 150/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17509.0524 - mean_absolute_error: 17509.0547 - val_loss: 23474.1969 - val_mean_absolute_error: 23474.1973\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 22624.77595\n",
      "Epoch 151/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17415.0352 - mean_absolute_error: 17415.0352 - val_loss: 23069.7555 - val_mean_absolute_error: 23069.7559\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 22624.77595\n",
      "Epoch 152/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 16965.7698 - mean_absolute_error: 16965.7715 - val_loss: 24170.6999 - val_mean_absolute_error: 24170.7012\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 22624.77595\n",
      "Epoch 153/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16643.7985 - mean_absolute_error: 16643.7988 - val_loss: 22814.3110 - val_mean_absolute_error: 22814.3125\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 22624.77595\n",
      "Epoch 154/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 17619.8339 - mean_absolute_error: 17619.8340 - val_loss: 22789.2442 - val_mean_absolute_error: 22789.2422\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 22624.77595\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 138us/step - loss: 17188.8792 - mean_absolute_error: 17188.8828 - val_loss: 22575.1901 - val_mean_absolute_error: 22575.1875\n",
      "\n",
      "Epoch 00155: val_loss improved from 22624.77595 to 22575.19012, saving model to CheckPoints/Weights-155--22575.19012.hdf5\n",
      "Epoch 156/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 17178.8679 - mean_absolute_error: 17178.8672 - val_loss: 22428.6405 - val_mean_absolute_error: 22428.6387\n",
      "\n",
      "Epoch 00156: val_loss improved from 22575.19012 to 22428.64052, saving model to CheckPoints/Weights-156--22428.64052.hdf5\n",
      "Epoch 157/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 17205.5110 - mean_absolute_error: 17205.5098 - val_loss: 26428.2361 - val_mean_absolute_error: 26428.2383\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 22428.64052\n",
      "Epoch 158/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 17294.9603 - mean_absolute_error: 17294.9629 - val_loss: 22403.8013 - val_mean_absolute_error: 22403.8008\n",
      "\n",
      "Epoch 00158: val_loss improved from 22428.64052 to 22403.80126, saving model to CheckPoints/Weights-158--22403.80126.hdf5\n",
      "Epoch 159/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 18306.5553 - mean_absolute_error: 18306.5566 - val_loss: 23603.9902 - val_mean_absolute_error: 23603.9922\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 22403.80126\n",
      "Epoch 160/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 18522.5058 - mean_absolute_error: 18522.5059 - val_loss: 25704.2133 - val_mean_absolute_error: 25704.2148\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 22403.80126\n",
      "Epoch 161/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17879.9688 - mean_absolute_error: 17879.9668 - val_loss: 22477.0703 - val_mean_absolute_error: 22477.0703\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 22403.80126\n",
      "Epoch 162/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 17080.6965 - mean_absolute_error: 17080.6973 - val_loss: 27636.5814 - val_mean_absolute_error: 27636.5801\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 22403.80126\n",
      "Epoch 163/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 17704.8843 - mean_absolute_error: 17704.8828 - val_loss: 23154.8511 - val_mean_absolute_error: 23154.8516\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 22403.80126\n",
      "Epoch 164/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17430.1099 - mean_absolute_error: 17430.1094 - val_loss: 22169.1133 - val_mean_absolute_error: 22169.1133\n",
      "\n",
      "Epoch 00164: val_loss improved from 22403.80126 to 22169.11328, saving model to CheckPoints/Weights-164--22169.11328.hdf5\n",
      "Epoch 165/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 17538.7882 - mean_absolute_error: 17538.7891 - val_loss: 24634.4201 - val_mean_absolute_error: 24634.4219\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 22169.11328\n",
      "Epoch 166/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 16702.0097 - mean_absolute_error: 16702.0098 - val_loss: 25058.4955 - val_mean_absolute_error: 25058.4941\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 22169.11328\n",
      "Epoch 167/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 18299.3703 - mean_absolute_error: 18299.3672 - val_loss: 26558.8149 - val_mean_absolute_error: 26558.8145\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 22169.11328\n",
      "Epoch 168/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16259.3940 - mean_absolute_error: 16259.3936 - val_loss: 23292.9920 - val_mean_absolute_error: 23292.9922\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 22169.11328\n",
      "Epoch 169/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16342.9389 - mean_absolute_error: 16342.9404 - val_loss: 22534.9045 - val_mean_absolute_error: 22534.9082\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 22169.11328\n",
      "Epoch 170/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 17237.5212 - mean_absolute_error: 17237.5176 - val_loss: 23594.1111 - val_mean_absolute_error: 23594.1113\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 22169.11328\n",
      "Epoch 171/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16644.3254 - mean_absolute_error: 16644.3262 - val_loss: 23051.9746 - val_mean_absolute_error: 23051.9746\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 22169.11328\n",
      "Epoch 172/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16914.9824 - mean_absolute_error: 16914.9805 - val_loss: 26006.7175 - val_mean_absolute_error: 26006.7148\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 22169.11328\n",
      "Epoch 173/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17279.5695 - mean_absolute_error: 17279.5684 - val_loss: 22482.9005 - val_mean_absolute_error: 22482.9004\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 22169.11328\n",
      "Epoch 174/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 16143.4892 - mean_absolute_error: 16143.4912 - val_loss: 23544.3207 - val_mean_absolute_error: 23544.3203\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 22169.11328\n",
      "Epoch 175/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 16819.1507 - mean_absolute_error: 16819.1504 - val_loss: 22025.0988 - val_mean_absolute_error: 22025.0977\n",
      "\n",
      "Epoch 00175: val_loss improved from 22169.11328 to 22025.09883, saving model to CheckPoints/Weights-175--22025.09883.hdf5\n",
      "Epoch 176/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 18225.0613 - mean_absolute_error: 18225.0625 - val_loss: 24232.2013 - val_mean_absolute_error: 24232.2012\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 22025.09883\n",
      "Epoch 177/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 16345.9770 - mean_absolute_error: 16345.9775 - val_loss: 22872.2179 - val_mean_absolute_error: 22872.2168\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 22025.09883\n",
      "Epoch 178/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 18425.1042 - mean_absolute_error: 18425.1035 - val_loss: 22171.6834 - val_mean_absolute_error: 22171.6836\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 22025.09883\n",
      "Epoch 179/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 16624.0883 - mean_absolute_error: 16624.0879 - val_loss: 22847.0077 - val_mean_absolute_error: 22847.0078\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 22025.09883\n",
      "Epoch 180/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16487.9746 - mean_absolute_error: 16487.9746 - val_loss: 23360.8156 - val_mean_absolute_error: 23360.8164\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 22025.09883\n",
      "Epoch 181/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 17354.4532 - mean_absolute_error: 17354.4512 - val_loss: 25179.2292 - val_mean_absolute_error: 25179.2285\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 22025.09883\n",
      "Epoch 182/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 17775.8528 - mean_absolute_error: 17775.8535 - val_loss: 24771.5544 - val_mean_absolute_error: 24771.5547\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 22025.09883\n",
      "Epoch 183/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16130.6665 - mean_absolute_error: 16130.6631 - val_loss: 22174.4173 - val_mean_absolute_error: 22174.4141\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 22025.09883\n",
      "Epoch 184/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 17290.3658 - mean_absolute_error: 17290.3672 - val_loss: 24207.7024 - val_mean_absolute_error: 24207.7012\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 22025.09883\n",
      "Epoch 185/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16073.8499 - mean_absolute_error: 16073.8496 - val_loss: 21625.0279 - val_mean_absolute_error: 21625.0293\n",
      "\n",
      "Epoch 00185: val_loss improved from 22025.09883 to 21625.02788, saving model to CheckPoints/Weights-185--21625.02788.hdf5\n",
      "Epoch 186/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 16273.6685 - mean_absolute_error: 16273.6680 - val_loss: 22259.5039 - val_mean_absolute_error: 22259.5039\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 21625.02788\n",
      "Epoch 187/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 149us/step - loss: 16857.3860 - mean_absolute_error: 16857.3828 - val_loss: 21839.7521 - val_mean_absolute_error: 21839.7520\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 21625.02788\n",
      "Epoch 188/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 16390.5727 - mean_absolute_error: 16390.5742 - val_loss: 22741.4003 - val_mean_absolute_error: 22741.4023\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 21625.02788\n",
      "Epoch 189/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 17392.7962 - mean_absolute_error: 17392.7930 - val_loss: 23148.3752 - val_mean_absolute_error: 23148.3750\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 21625.02788\n",
      "Epoch 190/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 16638.8702 - mean_absolute_error: 16638.8691 - val_loss: 26450.9149 - val_mean_absolute_error: 26450.9141\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 21625.02788\n",
      "Epoch 191/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 17922.6165 - mean_absolute_error: 17922.6172 - val_loss: 22273.3281 - val_mean_absolute_error: 22273.3281\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 21625.02788\n",
      "Epoch 192/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 16092.2433 - mean_absolute_error: 16092.2451 - val_loss: 23058.7719 - val_mean_absolute_error: 23058.7715\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 21625.02788\n",
      "Epoch 193/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16616.2851 - mean_absolute_error: 16616.2852 - val_loss: 21984.6682 - val_mean_absolute_error: 21984.6699\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 21625.02788\n",
      "Epoch 194/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16337.1785 - mean_absolute_error: 16337.1797 - val_loss: 21889.6783 - val_mean_absolute_error: 21889.6797\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 21625.02788\n",
      "Epoch 195/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 16122.6032 - mean_absolute_error: 16122.6025 - val_loss: 22538.7642 - val_mean_absolute_error: 22538.7656\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 21625.02788\n",
      "Epoch 196/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16279.6621 - mean_absolute_error: 16279.6611 - val_loss: 23120.9307 - val_mean_absolute_error: 23120.9297\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 21625.02788\n",
      "Epoch 197/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16287.2509 - mean_absolute_error: 16287.2539 - val_loss: 21493.7892 - val_mean_absolute_error: 21493.7852\n",
      "\n",
      "Epoch 00197: val_loss improved from 21625.02788 to 21493.78922, saving model to CheckPoints/Weights-197--21493.78922.hdf5\n",
      "Epoch 198/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 15778.6984 - mean_absolute_error: 15778.6982 - val_loss: 23750.8652 - val_mean_absolute_error: 23750.8652\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 21493.78922\n",
      "Epoch 199/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16289.3554 - mean_absolute_error: 16289.3564 - val_loss: 21572.7246 - val_mean_absolute_error: 21572.7266\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 21493.78922\n",
      "Epoch 200/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16982.2509 - mean_absolute_error: 16982.2500 - val_loss: 22010.8017 - val_mean_absolute_error: 22010.8008\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 21493.78922\n",
      "Epoch 201/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15990.0682 - mean_absolute_error: 15990.0703 - val_loss: 21677.2451 - val_mean_absolute_error: 21677.2441\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 21493.78922\n",
      "Epoch 202/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16121.8138 - mean_absolute_error: 16121.8154 - val_loss: 21591.9797 - val_mean_absolute_error: 21591.9805\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 21493.78922\n",
      "Epoch 203/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 15568.2685 - mean_absolute_error: 15568.2686 - val_loss: 21685.7391 - val_mean_absolute_error: 21685.7402\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 21493.78922\n",
      "Epoch 204/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15818.7761 - mean_absolute_error: 15818.7754 - val_loss: 22680.9486 - val_mean_absolute_error: 22680.9492\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 21493.78922\n",
      "Epoch 205/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15784.4945 - mean_absolute_error: 15784.4951 - val_loss: 22312.0690 - val_mean_absolute_error: 22312.0703\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 21493.78922\n",
      "Epoch 206/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15438.1595 - mean_absolute_error: 15438.1611 - val_loss: 22117.9625 - val_mean_absolute_error: 22117.9629\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 21493.78922\n",
      "Epoch 207/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15406.7629 - mean_absolute_error: 15406.7656 - val_loss: 22970.4080 - val_mean_absolute_error: 22970.4082\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 21493.78922\n",
      "Epoch 208/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15904.6925 - mean_absolute_error: 15904.6934 - val_loss: 24369.5856 - val_mean_absolute_error: 24369.5840\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 21493.78922\n",
      "Epoch 209/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16413.1407 - mean_absolute_error: 16413.1406 - val_loss: 21751.7824 - val_mean_absolute_error: 21751.7812\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 21493.78922\n",
      "Epoch 210/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 16063.2325 - mean_absolute_error: 16063.2295 - val_loss: 21955.5895 - val_mean_absolute_error: 21955.5898\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 21493.78922\n",
      "Epoch 211/1000\n",
      "1168/1168 [==============================] - 0s 145us/step - loss: 16036.1265 - mean_absolute_error: 16036.1250 - val_loss: 21591.8807 - val_mean_absolute_error: 21591.8809\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 21493.78922\n",
      "Epoch 212/1000\n",
      "1168/1168 [==============================] - 0s 144us/step - loss: 16798.5376 - mean_absolute_error: 16798.5371 - val_loss: 21449.6889 - val_mean_absolute_error: 21449.6875\n",
      "\n",
      "Epoch 00212: val_loss improved from 21493.78922 to 21449.68889, saving model to CheckPoints/Weights-212--21449.68889.hdf5\n",
      "Epoch 213/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 16468.0856 - mean_absolute_error: 16468.0859 - val_loss: 22643.2022 - val_mean_absolute_error: 22643.2012\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 21449.68889\n",
      "Epoch 214/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16011.1067 - mean_absolute_error: 16011.1064 - val_loss: 24491.9867 - val_mean_absolute_error: 24491.9863\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 21449.68889\n",
      "Epoch 215/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 16413.7655 - mean_absolute_error: 16413.7637 - val_loss: 22481.0053 - val_mean_absolute_error: 22481.0059\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 21449.68889\n",
      "Epoch 216/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15205.5341 - mean_absolute_error: 15205.5342 - val_loss: 21808.5261 - val_mean_absolute_error: 21808.5254\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 21449.68889\n",
      "Epoch 217/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 15101.5962 - mean_absolute_error: 15101.5957 - val_loss: 22079.0490 - val_mean_absolute_error: 22079.0469\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 21449.68889\n",
      "Epoch 218/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 15372.3881 - mean_absolute_error: 15372.3867 - val_loss: 21354.0164 - val_mean_absolute_error: 21354.0156\n",
      "\n",
      "Epoch 00218: val_loss improved from 21449.68889 to 21354.01643, saving model to CheckPoints/Weights-218--21354.01643.hdf5\n",
      "Epoch 219/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 16309.6533 - mean_absolute_error: 16309.6543 - val_loss: 21549.2472 - val_mean_absolute_error: 21549.2461\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 21354.01643\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 135us/step - loss: 17201.8589 - mean_absolute_error: 17201.8594 - val_loss: 22299.3809 - val_mean_absolute_error: 22299.3809\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 21354.01643\n",
      "Epoch 221/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15481.3060 - mean_absolute_error: 15481.3096 - val_loss: 21050.0141 - val_mean_absolute_error: 21050.0137\n",
      "\n",
      "Epoch 00221: val_loss improved from 21354.01643 to 21050.01407, saving model to CheckPoints/Weights-221--21050.01407.hdf5\n",
      "Epoch 222/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15144.8313 - mean_absolute_error: 15144.8320 - val_loss: 21809.4299 - val_mean_absolute_error: 21809.4297\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 21050.01407\n",
      "Epoch 223/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15505.4406 - mean_absolute_error: 15505.4414 - val_loss: 22122.4750 - val_mean_absolute_error: 22122.4727\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 21050.01407\n",
      "Epoch 224/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15379.9465 - mean_absolute_error: 15379.9482 - val_loss: 25109.5781 - val_mean_absolute_error: 25109.5762\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 21050.01407\n",
      "Epoch 225/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 15369.1877 - mean_absolute_error: 15369.1885 - val_loss: 21739.7792 - val_mean_absolute_error: 21739.7773\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 21050.01407\n",
      "Epoch 226/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16298.5007 - mean_absolute_error: 16298.5000 - val_loss: 24263.1068 - val_mean_absolute_error: 24263.1055\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 21050.01407\n",
      "Epoch 227/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15470.3331 - mean_absolute_error: 15470.3340 - val_loss: 22611.8709 - val_mean_absolute_error: 22611.8730\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 21050.01407\n",
      "Epoch 228/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 15626.0371 - mean_absolute_error: 15626.0381 - val_loss: 21527.7945 - val_mean_absolute_error: 21527.7949\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 21050.01407\n",
      "Epoch 229/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15309.8675 - mean_absolute_error: 15309.8682 - val_loss: 22193.0530 - val_mean_absolute_error: 22193.0547\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 21050.01407\n",
      "Epoch 230/1000\n",
      "1168/1168 [==============================] - 0s 147us/step - loss: 15470.1518 - mean_absolute_error: 15470.1504 - val_loss: 21713.1666 - val_mean_absolute_error: 21713.1680\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 21050.01407\n",
      "Epoch 231/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15056.3202 - mean_absolute_error: 15056.3203 - val_loss: 21089.5239 - val_mean_absolute_error: 21089.5234\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 21050.01407\n",
      "Epoch 232/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14971.0248 - mean_absolute_error: 14971.0254 - val_loss: 21227.1746 - val_mean_absolute_error: 21227.1738\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 21050.01407\n",
      "Epoch 233/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 15550.4330 - mean_absolute_error: 15550.4316 - val_loss: 23051.0482 - val_mean_absolute_error: 23051.0469\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 21050.01407\n",
      "Epoch 234/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16302.4907 - mean_absolute_error: 16302.4912 - val_loss: 22095.7497 - val_mean_absolute_error: 22095.7480\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 21050.01407\n",
      "Epoch 235/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15736.0316 - mean_absolute_error: 15736.0312 - val_loss: 21862.5711 - val_mean_absolute_error: 21862.5723\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 21050.01407\n",
      "Epoch 236/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 15886.3955 - mean_absolute_error: 15886.3975 - val_loss: 24000.1045 - val_mean_absolute_error: 24000.1035\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 21050.01407\n",
      "Epoch 237/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15016.7602 - mean_absolute_error: 15016.7588 - val_loss: 22398.8551 - val_mean_absolute_error: 22398.8535\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 21050.01407\n",
      "Epoch 238/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 15650.8851 - mean_absolute_error: 15650.8857 - val_loss: 20568.7312 - val_mean_absolute_error: 20568.7305\n",
      "\n",
      "Epoch 00238: val_loss improved from 21050.01407 to 20568.73116, saving model to CheckPoints/Weights-238--20568.73116.hdf5\n",
      "Epoch 239/1000\n",
      "1168/1168 [==============================] - 0s 132us/step - loss: 15019.5702 - mean_absolute_error: 15019.5703 - val_loss: 21075.7871 - val_mean_absolute_error: 21075.7871\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 20568.73116\n",
      "Epoch 240/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15146.5961 - mean_absolute_error: 15146.5977 - val_loss: 21097.9618 - val_mean_absolute_error: 21097.9648\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 20568.73116\n",
      "Epoch 241/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15346.2103 - mean_absolute_error: 15346.2090 - val_loss: 21171.5744 - val_mean_absolute_error: 21171.5742\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 20568.73116\n",
      "Epoch 242/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 16353.4008 - mean_absolute_error: 16353.3994 - val_loss: 21428.8289 - val_mean_absolute_error: 21428.8301\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 20568.73116\n",
      "Epoch 243/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14597.1421 - mean_absolute_error: 14597.1426 - val_loss: 21393.5704 - val_mean_absolute_error: 21393.5723\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 20568.73116\n",
      "Epoch 244/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14801.4164 - mean_absolute_error: 14801.4160 - val_loss: 21878.7908 - val_mean_absolute_error: 21878.7910\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 20568.73116\n",
      "Epoch 245/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 14725.9989 - mean_absolute_error: 14726.0000 - val_loss: 21083.5971 - val_mean_absolute_error: 21083.5996\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 20568.73116\n",
      "Epoch 246/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14980.6238 - mean_absolute_error: 14980.6250 - val_loss: 22097.3786 - val_mean_absolute_error: 22097.3789\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 20568.73116\n",
      "Epoch 247/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14730.9325 - mean_absolute_error: 14730.9336 - val_loss: 20832.7011 - val_mean_absolute_error: 20832.7012\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 20568.73116\n",
      "Epoch 248/1000\n",
      "1168/1168 [==============================] - 0s 144us/step - loss: 16100.8629 - mean_absolute_error: 16100.8633 - val_loss: 21134.6011 - val_mean_absolute_error: 21134.5996\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 20568.73116\n",
      "Epoch 249/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 17027.3197 - mean_absolute_error: 17027.3203 - val_loss: 22145.0799 - val_mean_absolute_error: 22145.0781\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 20568.73116\n",
      "Epoch 250/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15258.2298 - mean_absolute_error: 15258.2256 - val_loss: 21291.8464 - val_mean_absolute_error: 21291.8477\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 20568.73116\n",
      "Epoch 251/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14264.0526 - mean_absolute_error: 14264.0518 - val_loss: 21190.5510 - val_mean_absolute_error: 21190.5488\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 20568.73116\n",
      "Epoch 252/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14561.6179 - mean_absolute_error: 14561.6182 - val_loss: 23622.5905 - val_mean_absolute_error: 23622.5918\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 20568.73116\n",
      "Epoch 253/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15360.8180 - mean_absolute_error: 15360.8164 - val_loss: 20945.5860 - val_mean_absolute_error: 20945.5859\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 20568.73116\n",
      "Epoch 254/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 14423.8510 - mean_absolute_error: 14423.8506 - val_loss: 21056.8236 - val_mean_absolute_error: 21056.8262\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 20568.73116\n",
      "Epoch 255/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 14321.2693 - mean_absolute_error: 14321.2686 - val_loss: 21424.2848 - val_mean_absolute_error: 21424.2852\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 20568.73116\n",
      "Epoch 256/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15450.2997 - mean_absolute_error: 15450.2998 - val_loss: 21004.8924 - val_mean_absolute_error: 21004.8926\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 20568.73116\n",
      "Epoch 257/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14955.2657 - mean_absolute_error: 14955.2637 - val_loss: 21297.9257 - val_mean_absolute_error: 21297.9258\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 20568.73116\n",
      "Epoch 258/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15313.1596 - mean_absolute_error: 15313.1592 - val_loss: 22519.1544 - val_mean_absolute_error: 22519.1543\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 20568.73116\n",
      "Epoch 259/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15202.7012 - mean_absolute_error: 15202.7021 - val_loss: 20735.8129 - val_mean_absolute_error: 20735.8125\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 20568.73116\n",
      "Epoch 260/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15356.8398 - mean_absolute_error: 15356.8389 - val_loss: 22185.0628 - val_mean_absolute_error: 22185.0645\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 20568.73116\n",
      "Epoch 261/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 14504.7957 - mean_absolute_error: 14504.7959 - val_loss: 20895.3450 - val_mean_absolute_error: 20895.3457\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 20568.73116\n",
      "Epoch 262/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15907.0220 - mean_absolute_error: 15907.0244 - val_loss: 22861.4777 - val_mean_absolute_error: 22861.4785\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 20568.73116\n",
      "Epoch 263/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15053.0586 - mean_absolute_error: 15053.0596 - val_loss: 20829.5670 - val_mean_absolute_error: 20829.5664\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 20568.73116\n",
      "Epoch 264/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15280.4505 - mean_absolute_error: 15280.4502 - val_loss: 21061.9416 - val_mean_absolute_error: 21061.9434\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 20568.73116\n",
      "Epoch 265/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14594.9496 - mean_absolute_error: 14594.9482 - val_loss: 24214.0493 - val_mean_absolute_error: 24214.0508\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 20568.73116\n",
      "Epoch 266/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16541.1882 - mean_absolute_error: 16541.1914 - val_loss: 21515.1133 - val_mean_absolute_error: 21515.1133\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 20568.73116\n",
      "Epoch 267/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15356.2036 - mean_absolute_error: 15356.2021 - val_loss: 20743.7664 - val_mean_absolute_error: 20743.7656\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 20568.73116\n",
      "Epoch 268/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15087.9326 - mean_absolute_error: 15087.9316 - val_loss: 20768.2716 - val_mean_absolute_error: 20768.2715\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 20568.73116\n",
      "Epoch 269/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14597.9415 - mean_absolute_error: 14597.9414 - val_loss: 20771.7644 - val_mean_absolute_error: 20771.7637\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 20568.73116\n",
      "Epoch 270/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14863.0701 - mean_absolute_error: 14863.0703 - val_loss: 21147.6318 - val_mean_absolute_error: 21147.6328\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 20568.73116\n",
      "Epoch 271/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14367.7737 - mean_absolute_error: 14367.7725 - val_loss: 21647.7651 - val_mean_absolute_error: 21647.7656\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 20568.73116\n",
      "Epoch 272/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 14588.9489 - mean_absolute_error: 14588.9482 - val_loss: 21331.2389 - val_mean_absolute_error: 21331.2402\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 20568.73116\n",
      "Epoch 273/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14151.9701 - mean_absolute_error: 14151.9707 - val_loss: 21466.7703 - val_mean_absolute_error: 21466.7715\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 20568.73116\n",
      "Epoch 274/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15046.9880 - mean_absolute_error: 15046.9863 - val_loss: 21666.6710 - val_mean_absolute_error: 21666.6719\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 20568.73116\n",
      "Epoch 275/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14597.4617 - mean_absolute_error: 14597.4609 - val_loss: 25891.3029 - val_mean_absolute_error: 25891.2988\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 20568.73116\n",
      "Epoch 276/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15686.4078 - mean_absolute_error: 15686.4072 - val_loss: 21282.6453 - val_mean_absolute_error: 21282.6445\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 20568.73116\n",
      "Epoch 277/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15393.8708 - mean_absolute_error: 15393.8701 - val_loss: 21314.7893 - val_mean_absolute_error: 21314.7891\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 20568.73116\n",
      "Epoch 278/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15544.7886 - mean_absolute_error: 15544.7891 - val_loss: 22341.2630 - val_mean_absolute_error: 22341.2637\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 20568.73116\n",
      "Epoch 279/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14672.6083 - mean_absolute_error: 14672.6074 - val_loss: 21319.9201 - val_mean_absolute_error: 21319.9199\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 20568.73116\n",
      "Epoch 280/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14627.0211 - mean_absolute_error: 14627.0225 - val_loss: 20755.5231 - val_mean_absolute_error: 20755.5215\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 20568.73116\n",
      "Epoch 281/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14045.7613 - mean_absolute_error: 14045.7588 - val_loss: 23312.7952 - val_mean_absolute_error: 23312.7949\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 20568.73116\n",
      "Epoch 282/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 16627.9284 - mean_absolute_error: 16627.9336 - val_loss: 20938.1624 - val_mean_absolute_error: 20938.1621\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 20568.73116\n",
      "Epoch 283/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 14311.9765 - mean_absolute_error: 14311.9766 - val_loss: 21062.9778 - val_mean_absolute_error: 21062.9785\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 20568.73116\n",
      "Epoch 284/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 14885.7907 - mean_absolute_error: 14885.7930 - val_loss: 20642.0280 - val_mean_absolute_error: 20642.0293\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 20568.73116\n",
      "Epoch 285/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 14313.4240 - mean_absolute_error: 14313.4268 - val_loss: 20317.1856 - val_mean_absolute_error: 20317.1855\n",
      "\n",
      "Epoch 00285: val_loss improved from 20568.73116 to 20317.18557, saving model to CheckPoints/Weights-285--20317.18557.hdf5\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 133us/step - loss: 14002.8847 - mean_absolute_error: 14002.8857 - val_loss: 21016.9173 - val_mean_absolute_error: 21016.9160\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 20317.18557\n",
      "Epoch 287/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15123.8212 - mean_absolute_error: 15123.8223 - val_loss: 21325.3227 - val_mean_absolute_error: 21325.3203\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 20317.18557\n",
      "Epoch 288/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 15262.4049 - mean_absolute_error: 15262.4043 - val_loss: 20709.8561 - val_mean_absolute_error: 20709.8555\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 20317.18557\n",
      "Epoch 289/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13662.6172 - mean_absolute_error: 13662.6152 - val_loss: 20675.9229 - val_mean_absolute_error: 20675.9238\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 20317.18557\n",
      "Epoch 290/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 14310.7755 - mean_absolute_error: 14310.7744 - val_loss: 24140.4734 - val_mean_absolute_error: 24140.4727\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 20317.18557\n",
      "Epoch 291/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15443.6661 - mean_absolute_error: 15443.6680 - val_loss: 24382.5211 - val_mean_absolute_error: 24382.5234\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 20317.18557\n",
      "Epoch 292/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15135.2971 - mean_absolute_error: 15135.2998 - val_loss: 20717.0487 - val_mean_absolute_error: 20717.0488\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 20317.18557\n",
      "Epoch 293/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15065.1425 - mean_absolute_error: 15065.1436 - val_loss: 20864.6232 - val_mean_absolute_error: 20864.6230\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 20317.18557\n",
      "Epoch 294/1000\n",
      "1168/1168 [==============================] - 0s 177us/step - loss: 14686.1682 - mean_absolute_error: 14686.1660 - val_loss: 20367.3684 - val_mean_absolute_error: 20367.3691\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 20317.18557\n",
      "Epoch 295/1000\n",
      "1168/1168 [==============================] - 0s 192us/step - loss: 14019.5953 - mean_absolute_error: 14019.5938 - val_loss: 20832.2292 - val_mean_absolute_error: 20832.2285\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 20317.18557\n",
      "Epoch 296/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 13734.8359 - mean_absolute_error: 13734.8369 - val_loss: 20930.1878 - val_mean_absolute_error: 20930.1895\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 20317.18557\n",
      "Epoch 297/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13964.8878 - mean_absolute_error: 13964.8877 - val_loss: 21223.7939 - val_mean_absolute_error: 21223.7930\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 20317.18557\n",
      "Epoch 298/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15104.1552 - mean_absolute_error: 15104.1562 - val_loss: 21147.6460 - val_mean_absolute_error: 21147.6465\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 20317.18557\n",
      "Epoch 299/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14848.1596 - mean_absolute_error: 14848.1592 - val_loss: 20733.3935 - val_mean_absolute_error: 20733.3945\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 20317.18557\n",
      "Epoch 300/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 14862.6230 - mean_absolute_error: 14862.6211 - val_loss: 21821.1790 - val_mean_absolute_error: 21821.1797\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 20317.18557\n",
      "Epoch 301/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14063.3613 - mean_absolute_error: 14063.3604 - val_loss: 20895.2512 - val_mean_absolute_error: 20895.2500\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 20317.18557\n",
      "Epoch 302/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14211.4565 - mean_absolute_error: 14211.4551 - val_loss: 20792.0859 - val_mean_absolute_error: 20792.0859\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 20317.18557\n",
      "Epoch 303/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14148.0097 - mean_absolute_error: 14148.0078 - val_loss: 20375.9932 - val_mean_absolute_error: 20375.9922\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 20317.18557\n",
      "Epoch 304/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14153.6985 - mean_absolute_error: 14153.6982 - val_loss: 21419.0714 - val_mean_absolute_error: 21419.0723\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 20317.18557\n",
      "Epoch 305/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13802.0083 - mean_absolute_error: 13802.0107 - val_loss: 20437.5626 - val_mean_absolute_error: 20437.5625\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 20317.18557\n",
      "Epoch 306/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13632.6995 - mean_absolute_error: 13632.7002 - val_loss: 20654.1735 - val_mean_absolute_error: 20654.1738\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 20317.18557\n",
      "Epoch 307/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 13678.4906 - mean_absolute_error: 13678.4902 - val_loss: 20184.1834 - val_mean_absolute_error: 20184.1836\n",
      "\n",
      "Epoch 00307: val_loss improved from 20317.18557 to 20184.18343, saving model to CheckPoints/Weights-307--20184.18343.hdf5\n",
      "Epoch 308/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 14162.3813 - mean_absolute_error: 14162.3789 - val_loss: 20430.0387 - val_mean_absolute_error: 20430.0410\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 20184.18343\n",
      "Epoch 309/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13641.8107 - mean_absolute_error: 13641.8115 - val_loss: 20714.2042 - val_mean_absolute_error: 20714.2012\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 20184.18343\n",
      "Epoch 310/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14018.2680 - mean_absolute_error: 14018.2676 - val_loss: 21479.9990 - val_mean_absolute_error: 21480.0000\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 20184.18343\n",
      "Epoch 311/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15398.2197 - mean_absolute_error: 15398.2207 - val_loss: 24555.3856 - val_mean_absolute_error: 24555.3848\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 20184.18343\n",
      "Epoch 312/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 15541.2936 - mean_absolute_error: 15541.2959 - val_loss: 21715.7595 - val_mean_absolute_error: 21715.7578\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 20184.18343\n",
      "Epoch 313/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15275.3970 - mean_absolute_error: 15275.3994 - val_loss: 22103.1930 - val_mean_absolute_error: 22103.1914\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 20184.18343\n",
      "Epoch 314/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 15865.3346 - mean_absolute_error: 15865.3359 - val_loss: 22847.9526 - val_mean_absolute_error: 22847.9531\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 20184.18343\n",
      "Epoch 315/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 14078.7535 - mean_absolute_error: 14078.7539 - val_loss: 20444.2719 - val_mean_absolute_error: 20444.2715\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 20184.18343\n",
      "Epoch 316/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 13560.5849 - mean_absolute_error: 13560.5869 - val_loss: 21046.1557 - val_mean_absolute_error: 21046.1543\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 20184.18343\n",
      "Epoch 317/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13940.6769 - mean_absolute_error: 13940.6768 - val_loss: 21464.9322 - val_mean_absolute_error: 21464.9336\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 20184.18343\n",
      "Epoch 318/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 13339.2065 - mean_absolute_error: 13339.2070 - val_loss: 20736.4789 - val_mean_absolute_error: 20736.4805\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 20184.18343\n",
      "Epoch 319/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14815.4861 - mean_absolute_error: 14815.4844 - val_loss: 20999.3256 - val_mean_absolute_error: 20999.3262\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 20184.18343\n",
      "Epoch 320/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 14612.6155 - mean_absolute_error: 14612.6143 - val_loss: 21189.1896 - val_mean_absolute_error: 21189.1895\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 20184.18343\n",
      "Epoch 321/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14047.2357 - mean_absolute_error: 14047.2363 - val_loss: 20589.5895 - val_mean_absolute_error: 20589.5879\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 20184.18343\n",
      "Epoch 322/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13359.6964 - mean_absolute_error: 13359.6953 - val_loss: 20254.0999 - val_mean_absolute_error: 20254.0996\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 20184.18343\n",
      "Epoch 323/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13624.5647 - mean_absolute_error: 13624.5645 - val_loss: 20735.5924 - val_mean_absolute_error: 20735.5918\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 20184.18343\n",
      "Epoch 324/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13716.0806 - mean_absolute_error: 13716.0801 - val_loss: 20446.8053 - val_mean_absolute_error: 20446.8047\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 20184.18343\n",
      "Epoch 325/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13387.2474 - mean_absolute_error: 13387.2480 - val_loss: 20526.5092 - val_mean_absolute_error: 20526.5098\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 20184.18343\n",
      "Epoch 326/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13721.9627 - mean_absolute_error: 13721.9639 - val_loss: 20246.8915 - val_mean_absolute_error: 20246.8887\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 20184.18343\n",
      "Epoch 327/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 13816.9715 - mean_absolute_error: 13816.9697 - val_loss: 20494.1334 - val_mean_absolute_error: 20494.1328\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 20184.18343\n",
      "Epoch 328/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14169.3054 - mean_absolute_error: 14169.3047 - val_loss: 20758.2922 - val_mean_absolute_error: 20758.2910\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 20184.18343\n",
      "Epoch 329/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13481.7362 - mean_absolute_error: 13481.7344 - val_loss: 21673.2829 - val_mean_absolute_error: 21673.2812\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 20184.18343\n",
      "Epoch 330/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 14617.7667 - mean_absolute_error: 14617.7676 - val_loss: 21135.7381 - val_mean_absolute_error: 21135.7383\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 20184.18343\n",
      "Epoch 331/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13840.2059 - mean_absolute_error: 13840.2051 - val_loss: 21329.3938 - val_mean_absolute_error: 21329.3926\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 20184.18343\n",
      "Epoch 332/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 14053.6490 - mean_absolute_error: 14053.6494 - val_loss: 20614.2388 - val_mean_absolute_error: 20614.2402\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 20184.18343\n",
      "Epoch 333/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13589.1348 - mean_absolute_error: 13589.1357 - val_loss: 20526.9115 - val_mean_absolute_error: 20526.9102\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 20184.18343\n",
      "Epoch 334/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 14273.0971 - mean_absolute_error: 14273.0967 - val_loss: 21176.2174 - val_mean_absolute_error: 21176.2188\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 20184.18343\n",
      "Epoch 335/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13985.1538 - mean_absolute_error: 13985.1533 - val_loss: 21960.8098 - val_mean_absolute_error: 21960.8105\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 20184.18343\n",
      "Epoch 336/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 15899.8286 - mean_absolute_error: 15899.8291 - val_loss: 21243.0651 - val_mean_absolute_error: 21243.0625\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 20184.18343\n",
      "Epoch 337/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 14294.9709 - mean_absolute_error: 14294.9717 - val_loss: 20885.1224 - val_mean_absolute_error: 20885.1211\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 20184.18343\n",
      "Epoch 338/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13683.0720 - mean_absolute_error: 13683.0732 - val_loss: 20188.9234 - val_mean_absolute_error: 20188.9219\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 20184.18343\n",
      "Epoch 339/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13514.1733 - mean_absolute_error: 13514.1738 - val_loss: 20864.3139 - val_mean_absolute_error: 20864.3145\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 20184.18343\n",
      "Epoch 340/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 13929.1531 - mean_absolute_error: 13929.1523 - val_loss: 20146.7670 - val_mean_absolute_error: 20146.7676\n",
      "\n",
      "Epoch 00340: val_loss improved from 20184.18343 to 20146.76696, saving model to CheckPoints/Weights-340--20146.76696.hdf5\n",
      "Epoch 341/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 14112.8027 - mean_absolute_error: 14112.8027 - val_loss: 20542.0698 - val_mean_absolute_error: 20542.0703\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 20146.76696\n",
      "Epoch 342/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13582.8806 - mean_absolute_error: 13582.8799 - val_loss: 20084.7036 - val_mean_absolute_error: 20084.7051\n",
      "\n",
      "Epoch 00342: val_loss improved from 20146.76696 to 20084.70355, saving model to CheckPoints/Weights-342--20084.70355.hdf5\n",
      "Epoch 343/1000\n",
      "1168/1168 [==============================] - 0s 159us/step - loss: 13899.5750 - mean_absolute_error: 13899.5752 - val_loss: 20513.2704 - val_mean_absolute_error: 20513.2715\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 20084.70355\n",
      "Epoch 344/1000\n",
      "1168/1168 [==============================] - 0s 154us/step - loss: 13895.7480 - mean_absolute_error: 13895.7480 - val_loss: 20679.2060 - val_mean_absolute_error: 20679.2051\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 20084.70355\n",
      "Epoch 345/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13333.8477 - mean_absolute_error: 13333.8467 - val_loss: 20510.5361 - val_mean_absolute_error: 20510.5352\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 20084.70355\n",
      "Epoch 346/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 13620.8457 - mean_absolute_error: 13620.8457 - val_loss: 20312.1150 - val_mean_absolute_error: 20312.1152\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 20084.70355\n",
      "Epoch 347/1000\n",
      "1168/1168 [==============================] - 0s 158us/step - loss: 14085.9002 - mean_absolute_error: 14085.9004 - val_loss: 21612.2031 - val_mean_absolute_error: 21612.2051\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 20084.70355\n",
      "Epoch 348/1000\n",
      "1168/1168 [==============================] - 0s 183us/step - loss: 13295.2964 - mean_absolute_error: 13295.2969 - val_loss: 21413.9196 - val_mean_absolute_error: 21413.9219\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 20084.70355\n",
      "Epoch 349/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13908.2092 - mean_absolute_error: 13908.2080 - val_loss: 22619.5230 - val_mean_absolute_error: 22619.5215\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 20084.70355\n",
      "Epoch 350/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 13966.7002 - mean_absolute_error: 13966.7002 - val_loss: 20060.1469 - val_mean_absolute_error: 20060.1465\n",
      "\n",
      "Epoch 00350: val_loss improved from 20084.70355 to 20060.14694, saving model to CheckPoints/Weights-350--20060.14694.hdf5\n",
      "Epoch 351/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 13552.2034 - mean_absolute_error: 13552.2051 - val_loss: 21765.7679 - val_mean_absolute_error: 21765.7695\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 20060.14694\n",
      "Epoch 352/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 141us/step - loss: 15546.4964 - mean_absolute_error: 15546.4961 - val_loss: 20371.2383 - val_mean_absolute_error: 20371.2402\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 20060.14694\n",
      "Epoch 353/1000\n",
      "1168/1168 [==============================] - 0s 133us/step - loss: 13494.5224 - mean_absolute_error: 13494.5215 - val_loss: 21936.5014 - val_mean_absolute_error: 21936.5039\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 20060.14694\n",
      "Epoch 354/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 16129.1350 - mean_absolute_error: 16129.1357 - val_loss: 20456.3219 - val_mean_absolute_error: 20456.3223\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 20060.14694\n",
      "Epoch 355/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13726.9570 - mean_absolute_error: 13726.9551 - val_loss: 20627.0080 - val_mean_absolute_error: 20627.0078\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 20060.14694\n",
      "Epoch 356/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13502.3310 - mean_absolute_error: 13502.3311 - val_loss: 20413.7022 - val_mean_absolute_error: 20413.7012\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 20060.14694\n",
      "Epoch 357/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13754.0722 - mean_absolute_error: 13754.0732 - val_loss: 20258.0336 - val_mean_absolute_error: 20258.0352\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 20060.14694\n",
      "Epoch 358/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13544.9782 - mean_absolute_error: 13544.9785 - val_loss: 21707.7293 - val_mean_absolute_error: 21707.7285\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 20060.14694\n",
      "Epoch 359/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13601.5007 - mean_absolute_error: 13601.5000 - val_loss: 20751.0922 - val_mean_absolute_error: 20751.0938\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 20060.14694\n",
      "Epoch 360/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13395.1576 - mean_absolute_error: 13395.1562 - val_loss: 20249.7785 - val_mean_absolute_error: 20249.7793\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 20060.14694\n",
      "Epoch 361/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13468.3649 - mean_absolute_error: 13468.3662 - val_loss: 20742.6282 - val_mean_absolute_error: 20742.6309\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 20060.14694\n",
      "Epoch 362/1000\n",
      "1168/1168 [==============================] - 0s 140us/step - loss: 13638.0370 - mean_absolute_error: 13638.0371 - val_loss: 22774.8872 - val_mean_absolute_error: 22774.8848\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 20060.14694\n",
      "Epoch 363/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 15189.2968 - mean_absolute_error: 15189.2949 - val_loss: 21834.4918 - val_mean_absolute_error: 21834.4922\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 20060.14694\n",
      "Epoch 364/1000\n",
      "1168/1168 [==============================] - 0s 144us/step - loss: 13409.4698 - mean_absolute_error: 13409.4688 - val_loss: 20089.3520 - val_mean_absolute_error: 20089.3535\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 20060.14694\n",
      "Epoch 365/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13811.6324 - mean_absolute_error: 13811.6299 - val_loss: 19960.7442 - val_mean_absolute_error: 19960.7422\n",
      "\n",
      "Epoch 00365: val_loss improved from 20060.14694 to 19960.74422, saving model to CheckPoints/Weights-365--19960.74422.hdf5\n",
      "Epoch 366/1000\n",
      "1168/1168 [==============================] - 0s 134us/step - loss: 13470.0623 - mean_absolute_error: 13470.0615 - val_loss: 20326.0070 - val_mean_absolute_error: 20326.0078\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 19960.74422\n",
      "Epoch 367/1000\n",
      "1168/1168 [==============================] - 0s 154us/step - loss: 13466.7515 - mean_absolute_error: 13466.7500 - val_loss: 20184.1005 - val_mean_absolute_error: 20184.0996\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 19960.74422\n",
      "Epoch 368/1000\n",
      "1168/1168 [==============================] - 0s 195us/step - loss: 13360.0376 - mean_absolute_error: 13360.0391 - val_loss: 20029.8731 - val_mean_absolute_error: 20029.8730\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 19960.74422\n",
      "Epoch 369/1000\n",
      "1168/1168 [==============================] - 0s 204us/step - loss: 13906.1896 - mean_absolute_error: 13906.1904 - val_loss: 28414.6870 - val_mean_absolute_error: 28414.6875\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 19960.74422\n",
      "Epoch 370/1000\n",
      "1168/1168 [==============================] - 0s 185us/step - loss: 14958.8604 - mean_absolute_error: 14958.8613 - val_loss: 19939.4280 - val_mean_absolute_error: 19939.4277\n",
      "\n",
      "Epoch 00370: val_loss improved from 19960.74422 to 19939.42798, saving model to CheckPoints/Weights-370--19939.42798.hdf5\n",
      "Epoch 371/1000\n",
      "1168/1168 [==============================] - 0s 184us/step - loss: 13017.6469 - mean_absolute_error: 13017.6475 - val_loss: 19815.1170 - val_mean_absolute_error: 19815.1172\n",
      "\n",
      "Epoch 00371: val_loss improved from 19939.42798 to 19815.11697, saving model to CheckPoints/Weights-371--19815.11697.hdf5\n",
      "Epoch 372/1000\n",
      "1168/1168 [==============================] - 0s 182us/step - loss: 14012.8782 - mean_absolute_error: 14012.8789 - val_loss: 20134.3680 - val_mean_absolute_error: 20134.3672\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 19815.11697\n",
      "Epoch 373/1000\n",
      "1168/1168 [==============================] - 0s 174us/step - loss: 12879.8882 - mean_absolute_error: 12879.8867 - val_loss: 20118.8913 - val_mean_absolute_error: 20118.8887\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 19815.11697\n",
      "Epoch 374/1000\n",
      "1168/1168 [==============================] - 0s 148us/step - loss: 14629.4054 - mean_absolute_error: 14629.4043 - val_loss: 23744.5544 - val_mean_absolute_error: 23744.5566\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 19815.11697\n",
      "Epoch 375/1000\n",
      "1168/1168 [==============================] - 0s 149us/step - loss: 13995.5144 - mean_absolute_error: 13995.5146 - val_loss: 20613.6854 - val_mean_absolute_error: 20613.6855\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 19815.11697\n",
      "Epoch 376/1000\n",
      "1168/1168 [==============================] - 0s 175us/step - loss: 14931.8998 - mean_absolute_error: 14931.8994 - val_loss: 22371.8763 - val_mean_absolute_error: 22371.8750\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 19815.11697\n",
      "Epoch 377/1000\n",
      "1168/1168 [==============================] - 0s 154us/step - loss: 14016.1158 - mean_absolute_error: 14016.1152 - val_loss: 21905.0932 - val_mean_absolute_error: 21905.0938\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 19815.11697\n",
      "Epoch 378/1000\n",
      "1168/1168 [==============================] - 0s 159us/step - loss: 14420.1624 - mean_absolute_error: 14420.1631 - val_loss: 22192.0778 - val_mean_absolute_error: 22192.0781\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 19815.11697\n",
      "Epoch 379/1000\n",
      "1168/1168 [==============================] - 0s 149us/step - loss: 13334.7629 - mean_absolute_error: 13334.7637 - val_loss: 20479.6074 - val_mean_absolute_error: 20479.6035\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 19815.11697\n",
      "Epoch 380/1000\n",
      "1168/1168 [==============================] - 0s 146us/step - loss: 13175.2161 - mean_absolute_error: 13175.2168 - val_loss: 20600.6137 - val_mean_absolute_error: 20600.6133\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 19815.11697\n",
      "Epoch 381/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 15615.2920 - mean_absolute_error: 15615.2910 - val_loss: 26109.7044 - val_mean_absolute_error: 26109.7051\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 19815.11697\n",
      "Epoch 382/1000\n",
      "1168/1168 [==============================] - 0s 143us/step - loss: 13906.5922 - mean_absolute_error: 13906.5938 - val_loss: 20374.3813 - val_mean_absolute_error: 20374.3828\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 19815.11697\n",
      "Epoch 383/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 13243.9322 - mean_absolute_error: 13243.9326 - val_loss: 20196.4819 - val_mean_absolute_error: 20196.4824\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 19815.11697\n",
      "Epoch 384/1000\n",
      "1168/1168 [==============================] - 0s 135us/step - loss: 13005.5516 - mean_absolute_error: 13005.5508 - val_loss: 21176.2489 - val_mean_absolute_error: 21176.2480\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 19815.11697\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 159us/step - loss: 13408.3922 - mean_absolute_error: 13408.3926 - val_loss: 20185.4706 - val_mean_absolute_error: 20185.4707\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 19815.11697\n",
      "Epoch 386/1000\n",
      "1168/1168 [==============================] - 0s 161us/step - loss: 14071.7579 - mean_absolute_error: 14071.7598 - val_loss: 20100.4640 - val_mean_absolute_error: 20100.4629\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 19815.11697\n",
      "Epoch 387/1000\n",
      "1168/1168 [==============================] - 0s 152us/step - loss: 13903.1274 - mean_absolute_error: 13903.1279 - val_loss: 20257.0932 - val_mean_absolute_error: 20257.0957\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 19815.11697\n",
      "Epoch 388/1000\n",
      "1168/1168 [==============================] - 0s 150us/step - loss: 13385.1221 - mean_absolute_error: 13385.1201 - val_loss: 19690.8272 - val_mean_absolute_error: 19690.8262\n",
      "\n",
      "Epoch 00388: val_loss improved from 19815.11697 to 19690.82722, saving model to CheckPoints/Weights-388--19690.82722.hdf5\n",
      "Epoch 389/1000\n",
      "1168/1168 [==============================] - 0s 139us/step - loss: 13094.2215 - mean_absolute_error: 13094.2207 - val_loss: 20221.4899 - val_mean_absolute_error: 20221.4883\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 19690.82722\n",
      "Epoch 390/1000\n",
      "1168/1168 [==============================] - 0s 157us/step - loss: 13069.9275 - mean_absolute_error: 13069.9268 - val_loss: 20099.6701 - val_mean_absolute_error: 20099.6699\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 19690.82722\n",
      "Epoch 391/1000\n",
      "1168/1168 [==============================] - 0s 162us/step - loss: 13380.3646 - mean_absolute_error: 13380.3633 - val_loss: 20610.8998 - val_mean_absolute_error: 20610.9004\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 19690.82722\n",
      "Epoch 392/1000\n",
      "1168/1168 [==============================] - 0s 153us/step - loss: 13396.2904 - mean_absolute_error: 13396.2891 - val_loss: 20124.2582 - val_mean_absolute_error: 20124.2578\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 19690.82722\n",
      "Epoch 393/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 13305.8000 - mean_absolute_error: 13305.7998 - val_loss: 21469.4103 - val_mean_absolute_error: 21469.4121\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 19690.82722\n",
      "Epoch 394/1000\n",
      "1168/1168 [==============================] - 0s 141us/step - loss: 13266.0264 - mean_absolute_error: 13266.0254 - val_loss: 21896.8827 - val_mean_absolute_error: 21896.8809\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 19690.82722\n",
      "Epoch 395/1000\n",
      "1168/1168 [==============================] - 0s 138us/step - loss: 12797.7090 - mean_absolute_error: 12797.7109 - val_loss: 21294.5516 - val_mean_absolute_error: 21294.5508\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 19690.82722\n",
      "Epoch 396/1000\n",
      "1168/1168 [==============================] - 0s 137us/step - loss: 13862.1794 - mean_absolute_error: 13862.1797 - val_loss: 20402.0167 - val_mean_absolute_error: 20402.0176\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 19690.82722\n",
      "Epoch 397/1000\n",
      "1168/1168 [==============================] - 0s 136us/step - loss: 15330.4349 - mean_absolute_error: 15330.4385 - val_loss: 20392.6179 - val_mean_absolute_error: 20392.6172\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 19690.82722\n",
      "Epoch 398/1000\n",
      "1168/1168 [==============================] - 0s 142us/step - loss: 14755.2414 - mean_absolute_error: 14755.2393 - val_loss: 22379.4725 - val_mean_absolute_error: 22379.4727\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 19690.82722\n",
      "Epoch 399/1000\n",
      " 480/1168 [===========>..................] - ETA: 0s - loss: 15577.7048 - mean_absolute_error: 15577.7041"
     ]
    }
   ],
   "source": [
    "hist=model.fit(XT,YT,epochs=1000,batch_size=32,validation_split=0.2,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHRCAYAAABzdSAxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd4FNXCBvB3djdlk2waSYAAodfQxFCUgAoX8SL2QrliARsf4MVrAVFABAQsWGgqdhApYkNRURQRCC0QAqFDEkglPdlN2TLz/bHJZHezqRsIs7y/5/F5ktmzsycnmHdOmTOCJEkSiIiISPFUTV0BIiIiahwMdSIiIjfBUCciInITDHUiIiI3wVAnIiJyEwx1IiIiN6Fp6gq4IiurqNHPGRTkg7y84kY/77WEbeg6tqHr2IaNg+3ousZuw9BQXbWvsafuQKNRN3UVFI9t6Dq2oevYho2D7ei6K9mGDHUiIiI3wVAnIiJyEwx1IiIiN8FQJyIichMMdSIiIjfBUCciInITDHUiIiI3oejNZ4iISLmWLXsHp06dQG5uDkpLSxEe3gqBgUFYsGBJre89c+YUdu3aiccee8Lp63v37kFmZgbuuuveBtcvOjoKd999H55//iX52Lvvvoldu3bim2+2yMcefXQ8evXqg+eemyEfu/nmQejZszcAwNNTA6PRjLlzFyA0NKzB9akLhjoRETWJadOeBQBs3boFyclJmDx5Wp3f27lzV3Tu3LXa1wcNutHl+gUEBCAu7hDMZjM0Gg0sFgtOnjxhVyY+Pg4dO3bEoUMHUFxsgI+PLwDA3z8Ay5d/BMC6A9zl2AHVGYY6ERFh459nceDkpSrH1WoBFovUoHP27xaGB4d1qvf7Dh06iFWrlsHDwwN33nkPvLy88O23myBJ1nosWPAGzp8/ix9+2Ix58xZh7Nh70KtXH1y4kIzg4GAsWPAGfvttK5KTk3D33ffh1VdfRlhYc6SmpqBHj0g8//xLyM/Px7x5L8NkMqFNm7Y4dOgANmz43uFn16Bv3+tx4MA+3HDDYOzfvxdRUQPw668/y2W2bPkeN988HGFhLfDLLz/hvvvGNKitGgvn1ImI6KpjNBqxcuXHuO2223Hx4gW8+eZ7WL78I0REtMX+/TF2ZdPSUvH440/jww8/Q35+Hk6cOG73+sWLF/DSS7OxevUXiInZjZycbHz55ScYMuRmLF/+EYYNGw6LxeK0HiNG3Ibt27cBAP7441fceutt8msGgx7x8XG44YZo3H77nfjuu83ya4WFBZg69UlMnfokJkyYgHnzXmmspqkRe+pERIQHh3Vy2qu+kkPHtiIi2spfBwUFY8GCufDx8UFycpI8V10hICAQzZu3AACEhTWH0Vhm93qrVq3lYfFmzUJgNBqRlJSEf/97NACgd+/rqq1H7959sHTpYhQU5KOgoADNm7eUX9u27VeIooQXX7ROI+TkZOPgwf2IihrA4XciIqIKKpUAANDr9fjkkw+xefNPAIBnn50iD8NXEAShxnM5e71Dh444duwoOnfuioSEozW+d9CgwXjrrcUYMuRmu9e2bPkeS5YsRYcOHQEA27b9gm+/3YSoqAG1/nyXC0OdiIiuWr6+vujVqw8mTnwIWq0WOp0O2dlZaNky3KXzPvTQo5g/fw7+/PN3hISEQqOpPg5vvfXfePzxCXjhhVnysdOnTwKQ5EAHgJtuGob331+KzMwMefgdqFz9/vTTU6uMMjQ2QXK85FGQyzGc0VRDTe6Ebeg6tqHr2IaNw13bMSZmFwIDg9C9eyQOHNiHNWs+w/vvf3BZPqux27Cm56mzp05ERNecli1bYdGi16BWqyGKIqZPf76pq9QoGOo2ioqNCBYVO3BBRER11K5de3z44WdNXY1Gx1vayhlKTXhuxR6s++1kU1eFiIioQRjq5QylZpgtInILSpu6KkRERA3CUHcggcPvRESkTHWaUz9y5AjeeustrFmzBs8++yyys7MBAKmpqejTpw/eeecdPP3008jPz4eHhwe8vLzw8ccfIzk5GTNnzoQgCOjcuTPmzp0LlUqF5cuXY8eOHdBoNJg1axZ69+5dbdkrpea7HImIiK5+tabm6tWr8corr6CszLpDzzvvvIM1a9Zg+fLl0Ol0eOkl69NrLly4gK+//hpr1qzBxx9/DABYtGgRpk+fjnXr1kGSJGzfvh0JCQnYv38/Nm3ahKVLl2LevHnVliUiIvc1ZcoTiI09YHfs3XffwpYt3zstn56ehieffBQAMHfuSzCZTHav7927BwsXvlrt55WVlcnn3rp1C3bt+rvBdU9PT0N0dBTWrv3c7viMGc/K96dXfObgwYOxbt2Xdu+99dab5G1kK/6rbqva+qg11CMiIrBs2bIqx5ctW4aHHnoIYWFhyM7ORmFhIZ5++mmMGzcOf/31FwAgISEBAwZYd9YZOnQo9uzZg9jYWERHR0MQBISHh8NisSA3N9dp2aag3Lv2iYiU5c4777F7OIrJZMLu3f/gX/8aWet7581bBA8Pj3p9Xm5ujhzqo0bdgejom+pXYQetWrXGjh1/yt8XFhYgJeWiXZm///4To0aNwtatP0EURfl4u3btsXz5R3b/qdVql+oD1GH4feTIkUhJSbE7lpOTg5iYGLmXbjKZMHHiRDz88MMoKCjAuHHj0Lt3b0iSJG/P5+vri6KiIuj1egQGBsrnqjjurGxtgoJ8oNG43ggAINo0Zk039lPdsA1dxzZ0Hduw7tbEbcbei4ca9ZyD2vTDhL73Vfv6Aw/cjU8++QB+fhpotVr88ssvGDo0GhERYdi/fz+WL18OACgtLcWSJUsQHOwLDw81QkN1GDZsGH755RekpKRg1qxZ0Gq10Gq1CAgIQGioDmvXrsW2bdtgNpuh0+mwbNkyvPfeGiQnJ2LDhi8gSRJCQkIwbtw4LF68GLGxsQCA0aNH45FHHsHMmTPh6emJ1NRUXLp0CYsXL0ZkZKRc97IyX4SENENgYCAKCy+hY8eO+P33Lbj99lE4ePCg/G/v11+34OWXX0Zubi6OHz+EW265BWVllT9HY2vQfeq//vorRo8eLV9VhISEYOzYsdBoNGjWrBm6d++OxMREuzlxg8EAf39/+Pn5wWAw2B3X6XROy9YmL6+4IdV3Kje/RP7aHXdPupLcdQeqK4lt6Dq2Yf0UlxhhcbJPh1olOD1e13PW9ju48cYh+PbbLbj11n9j/fqNeOKJ/0NWVhEOHz6Gl156FSEhofjyy0+xefMPuPXWf8NksiArqwgWi4isrCK88cZbeOSRx9G//yCsXfs5kpOTkJlZgNTUTLz55jKoVCr8739T8c8/+/DggxOQkHACY8Y8gk8++RDe3qX4/vutOHcuCStWfAKLxYLJkyeha9feKC01ITS0JaZNewE//vgdvvhird02sbm5BphMFgwdOhybNn2HSZOewi+/bMNTT03Bnj17kZVVhIsXL6CoSI9u3bph+PB/47PPvkTPnlHIzTXgzJmzGDNmnHy+rl27y8+Xr02j7ygXExODyZMny9/v2bMHX331FT766CMYDAacOXMGHTp0QI8ePbBv3z4MHDgQO3fuxKBBgxAREYE333wTkyZNQkZGBkRRRHBwsNOyVxRXyhHRNezeTqNxb6fRVY5f7oujO+64BytWvId+/aJQVFSErl27lX9uKN59901otT7IyrqEXr36OH1/YuJ5dO/eEwDQq1dfJCcnQaVSwcPDA6+++jK0Wi0uXboEs9ns9P3JyYno06cvBEGARqNBZGQvJCWdBwB07twVgPXJb0ePHnH6/iFDbsaUKY9j1Kg70KxZM3h7e8uvbdnyPUpKSjFp0iQYjWYcPRqPlJSLUKvV8vB7Y2vQ8vLExES0adNG/v6mm25C27Zt8eCDD2LSpEn43//+h+DgYMyYMQPLli3DmDFjYDKZMHLkSPTs2RNRUVEYM2YMpk2bhjlz5gCA07JNQcFb4RMRKU7Hjp1QUmLAxo1f4/bb75SPL1myALNmzcXLL1t769WJiGiHY8fiAQAnTyYAAM6ePYOdO3fgtdcW4dlnX4QkWeeyBUElf12hbdv2iI+PAwCYzWYcOxaP1q0jysvX3tvz8fFBRERbrFz5PkaMqHzWutlsxvbt27By5Wp88sknWLp0OR566BF8992mujRLg9Wpp966dWts3LhR/v7nn3+uUubll1+ucqx9+/ZYu3ZtlePTpk3DtGnT6lT2ShHYVSciahK3334nVqx4X368KgCMHDkKTz75KHQ6HYKCmiE7O8vpe597bibmzn0JX3+9BoGBgfD09ELr1m2g1WoxadIEeHp6oFmzEGRnZyEyshdMJjNWrnwfXl5eAIDBg4fg8OFYPPXUYzCZTBg27F/yaEFdjRjxb7z55kK8+upCeaHc7t070bVrd/j7B9j9nI8+Og6jR9+NpKREu1XyADBr1lyEh7eq12c74lPayuUUlOKFVXtw8/Wt8fCILo123msR5zJdxzZ0HduwcbAdXXcln9LGHeXK1WGUhYiI6KrGUCciInITDHVHip2MICKiax1DnYiIyE0w1B0od9kgERFd6xjq5epyPyIREdHVjKHugM9TJyIipWKoExERuQmGuiN21ImISKEY6uU4pU5ERErHUCciInITDHUHHH0nIiKlYqiX4+g7EREpHUPdgYIfWkdERNc4hnoFrpQjIiKFY6g7YD+diIiUiqFejv10IiJSOoa6I3bViYhIoRjqFdhVJyIihWOoExERuQmGugM+pY2IiJSKoV6Oo+9ERKR0DHUH3HuGiIiUiqFeTuDmM0REpHAMdSIiIjfBUCciInITDHUHfKALEREpFUO9HKfUiYhI6RjqREREboKh7oCj70REpFQM9XIcfSciIqVjqBMREbkJhrpMgOCbDzPKmroiREREDcJQL6c36uHVYy8yPeKauipEREQNwlAvZ5SMEARAFExNXRUiIqIGYag74OJ3IiJSKoZ6FYx1IiJSJoY6ERGRm2CoExERuQmGejkVN38nIiKFY6g74Iw6EREpFUO9nMCNYomISOEY6o74RBciIlIohnoFdtSJiEjhGOrlOPxORERKx1AvVxHpHHwnIiKlYqhXYEediIgUjqFORETkJhjq5So76hyAJyIiZWKolxO4oxwRESlcnUL9yJEjmDBhAgAgISEBQ4YMwYQJEzBhwgRs3boVALB8+XLcf//9GDt2LOLj4wEAycnJGDduHMaPH4+5c+dCFMV6l71yuFSOiIiUTVNbgdWrV+PHH3+EVqsFABw/fhyPPfYYJk6cKJdJSEjA/v37sWnTJqSnp2PatGnYvHkzFi1ahOnTp2PgwIGYM2cOtm/fjvDw8DqXHTFixOX7yavBSCciIqWqtaceERGBZcuWyd8fO3YMO3bswH/+8x/MmjULer0esbGxiI6OhiAICA8Ph8ViQW5uLhISEjBgwAAAwNChQ7Fnz556lb2SOPpORERKV2tPfeTIkUhJSZG/7927Nx544AH07NkTq1atwooVK6DT6RAYGCiX8fX1RVFRESRJkueqK47p9fo6l61NUJAPNBp13X/aGohFJvnr0FBdo5zzWsY2dB3b0HVsw8bBdnTdlWrDWkPd0YgRI+Dv7y9/PX/+fAwfPhwGg0EuYzAYoNPpoFKp7I75+/vDz8+vzmVrk5dXXN/qV3+u4so6ZWXVfkFB1QsN1bENXcQ2dB3bsHGwHV3X2G1Y0wVCvVe/T5o0SV7cFhMTg8jISPTr1w+7du2CKIpIS0uDKIoIDg5Gjx49sG/fPgDAzp07ERUVVa+yREREVHf17qm/+uqrmD9/Pjw8PBASEoL58+fDz88PUVFRGDNmDERRxJw5cwAAM2bMwOzZs7F06VJ06NABI0eOhFqtrnPZpsGlckREpEyCJCn3WaONOZyRW5KP2TGvQ2dsi8W3TWm0816LOFznOrah69iGjYPt6Lqrevjd3Sn3EoeIiK51DPVyKjYFEREpHJOMiIjITTDUK7AliIhI4RhlREREboKhXo6PXiUiIqVjqJcTwM3fiYhI2RjqDthPJyIipWKolxP4mDYiIlI4hjoREZGbYKhXwQF4IiJSJoZ6OS6UIyIipWOoO2A/nYiIlIqhXoEddSIiUjiGOhERkZtgqFfBAXgiIlImhno5eaEcM52IiBSKoe6Ic+tERKRQDPVyzHIiIlI6hjoREZGbYKg7kCROqhMRkTIx1GUcgCciImVjqBMREbkJhno5PnmViIiUjqFORETkJhjqREREboKhLuP4OxERKRtD3YHEfWKJiEihGOrl2E8nIiKlY6gTERG5CYY6ERGRm2CoyzgAT0REysZQd8CFckREpFQM9XICt5QjIiKFY6gTERG5CYY6ERGRm2Col+PgOxERKR1DvQoulCMiImViqMvYVyciImVjqBMREbkJhjoREZGbYKiX4+A7EREpHUPdAZfJERGRUjHUK8g7yjHWiYhImRjqREREboKhTkRE5CYY6uW4UI6IiJSOoU5EROQmGOrlBPbViYhI4RjqREREboKh7kDiLW1ERKRQmroUOnLkCN566y2sWbMGJ06cwPz586FWq+Hp6YklS5YgJCQECxYswKFDh+Dr6wsAWLlyJUwmE55//nmUlpYiLCwMixYtglarxcaNG7F+/XpoNBpMnjwZt9xyC3Jzc52WJSIiorqptae+evVqvPLKKygrKwMALFy4ELNnz8aaNWswYsQIrF69GgCQkJCAjz/+GGvWrMGaNWug0+mwcuVKjB49GuvWrUOPHj2wYcMGZGVlYc2aNVi/fj0++eQTLF26FEaj0WlZIiIiqrtaQz0iIgLLli2Tv1+6dCm6d+8OALBYLPDy8oIoikhOTsacOXMwduxYfPPNNwCA2NhYDBkyBAAwdOhQ7NmzB/Hx8bjuuuvg6ekJnU6HiIgInDx50mnZK0kQuFCOiIiUrdbh95EjRyIlJUX+PiwsDABw6NAhrF27Fl999RWKi4vx0EMP4bHHHoPFYsHDDz+Mnj17Qq/XQ6fTAQB8fX1RVFRkd6ziuF6vd1q2NkFBPtBo1PX7iashiqL1CwkIDdXVXJhqxTZ0HdvQdWzDxsF2dN2VasM6zak72rp1K1atWoWPPvoIwcHBcpBXzIEPGjQIJ0+ehJ+fHwwGA7y9vWEwGODv7y8fq2AwGKDT6ZyWrU1eXnFDqu+UKJWHuiAhK6v2CwqqXmiojm3oIrah69iGjYPt6LrGbsOaLhDqvfr9hx9+wNq1a7FmzRq0adMGAJCUlITx48fDYrHAZDLh0KFDiIyMRL9+/fD3338DAHbu3Inrr78evXv3RmxsLMrKylBUVIRz586hS5cuTssSERFR3dWrp26xWLBw4UK0bNkS06ZNAwD0798fzzzzDO644w48+OCD8PDwwF133YXOnTtj8uTJmDFjBjZu3IigoCC8/fbb8PHxwYQJEzB+/HhIkoRnn30WXl5eTssSERFR3QmSJCn2xuzGHM6QJAlT/5oBj9JQvDvqhUY777WIw3WuYxu6jm3YONiOrruqh9/dnXIvcYiI6FrHUHckMNWJiEiZGOrl5PvUmelERKRQDHUiIiI3wVAnIiJyEwx1IiIiN8FQJyIichMMdVtcJEdERArGUK+CyU5ERMrEUHfASCciIqViqBMREbkJhjoREZGbYKjbEZq6AkRERA3GUK+Cs+pERKRMDHUiIiI3wVAnIiJyEwx1IiIiN8FQJyIichMMdQcSF8ATEZFCMdRtMdGJiEjBGOqOJN7SRkREysRQJyIichMMdSIiIjfBUHfEaXUiIlIohrojTqkTEZFCMdQdsadOREQKxVC3w0QnIiLlYqg74i1tRESkUAx1IiIiN8FQJyIichMMdUecViciIoViqDvglDoRESkVQ52IiMhNMNQdCeyqExGRMjHU7XBCnYiIlIuhTkRE5CYY6rY48k5ERArGULfF0XciIlIwhjoREZGbYKjb4vA7EREpGEO9CiY7EREpE0PdDifViYhIuRjqREREboKhTkRE5CYY6jY4+E5ERErGUHcgcaEcEREpFEOdiIjITTDUiYiI3ARDnYiIyE0w1O1wqRwRESkXQ52IiMhN1CnUjxw5ggkTJgAAkpOTMW7cOIwfPx5z586FKIoAgOXLl+P+++/H2LFjER8f32hliYiIqG5qDfXVq1fjlVdeQVlZGQBg0aJFmD59OtatWwdJkrB9+3YkJCRg//792LRpE5YuXYp58+Y1SlkiIiKqu1pDPSIiAsuWLZO/T0hIwIABAwAAQ4cOxZ49exAbG4vo6GgIgoDw8HBYLBbk5ua6XLZp8D51IiJSJk1tBUaOHImUlBT5e0mSIAjWBWW+vr4oKiqCXq9HYGCgXKbiuKtlaxMU5AONRl3HH7UurJ8fGqprxHNem9iGrmMbuo5t2DjYjq67Um1Ya6g7UqkqO/cGgwH+/v7w8/ODwWCwO67T6VwuW5u8vOL6Vr8W1l56VlbtFxRUvdBQHdvQRWxD17ENGwfb0XWN3YY1XSDUe/V7jx49sG/fPgDAzp07ERUVhX79+mHXrl0QRRFpaWkQRRHBwcEul73yeEsbEREpV7176jNmzMDs2bOxdOlSdOjQASNHjoRarUZUVBTGjBkDURQxZ86cRilLREREdSdIkqTYlWGNPSQ09ffZkEweWDFqTqOe91rD4TrXsQ1dxzZsHGxH113Vw+9ERER0dWKoV6HYgQsiIrrGMdSJiIjcBEOdiIjITTDUiYiI3ARD3YYg8T51IiJSLoa6Ay6TIyIipWKoExERuQmGOhERkZtgqDsSOABPRETKxFB3xEwnIiKFYqg74gJ4IiJSKIa6HSY6EREpF0PdEYffiYhIoRjqjthZJyIihWKoExERuQmGehUcfyciImViqNvh2DsRESkXQ90GI52IiJSMoU5EROQmGOpERERugqFORETkJhjqREREboKhTkRE5CYY6lXwPnUiIlImhrod3tRGRETKxVAnIiJyEwx1IiIiN8FQJyIichMMdUecViciIoViqBMREbkJhnoVvKWNiIiUiaFuQ+DYOxERKRhDnYiIyE0w1ImIiNwEQ90JSeK8OhERKQ9DnYiIyE0w1O1YF8qxn05ERErEUCciInITDHUiIiI3wVB3huPvRESkQAz1KpjoRESkTAx1JyQGOxERKRBDnYiIyE0w1B0JAPeeISIiJWKo2+ADXYiISMkY6kRERG6Coe4Eh9+JiEiJGOpOMdWJiEh5GOpVSBCZ6UREpEAMdRvyQjmGOhERKZCmIW/69ttv8d133wEAysrKcOLECbz99tt444030LJlSwDAtGnTEBUVhVdffRWnTp2Cp6cnFixYgLZt2yIuLg4LFy6EWq1GdHQ0pk6dClEUnZZtCiIn1YmISIEaFOr33nsv7r33XgDAvHnzcN999yEhIQEvvPACRo4cKZfbtm0bjEYjNmzYgLi4OCxevBirVq3C3LlzsWzZMrRp0wZPPvkkEhISkJqa6rQsERER1Y1Lw+9Hjx7F2bNnMWbMGCQkJGDz5s0YP348Fi9eDLPZjNjYWAwZMgQA0LdvXxw7dgx6vR5GoxEREREQBAHR0dGIiYlxWrZJCIDEnjoRESmQS6H+4YcfYsqUKQCAwYMHY/bs2fjqq69QXFyM9evXQ6/Xw8/PTy6vVqurHPP19UVRUZHTsmaz2ZXq1R+n1ImISMEaNPwOAIWFhTh//jwGDRoEALjvvvvg7+8PABg+fDh+++036HQ6GAwG+T2iKMLPz8/umMFggL+/P0pLS6uU1Whqrl5QkA80GnVDf4QqVIIASEBwsB/8fT0b7bzXotBQXVNXQfHYhq5jGzYOtqPrrlQbNjjUDxw4gBtvvBGAdbj6zjvvxPr169GiRQvExMQgMjISISEh+OuvvzBq1CjExcWhS5cu8PPzg4eHBy5cuIA2bdpg165dmDp1KjIyMqqUrU1eXnFDq+9Uxah7dnYRyooZ6g0VGqpDVlZRU1dD0diGrmMbNg62o+sauw1rukBocKgnJiaidevWAABBELBgwQJMnToV3t7e6NixIx588EGo1Wrs3r0bY8eOhSRJeP311wFYF9c9//zzsFgsiI6ORp8+fdCrVy+nZZsCh9+JiEiJBEnBq8Ia++rxf7+/jlJJj0WDX0UAh98bjFf2rmMbuo5t2DjYjq67kj11bj5jo3LzGcVe5xAR0TWMoe4Et4klIiIlYqgTERG5CYa6EwpeZkBERNcwhroTzHQiIlIihroNQbAulGNPnYiIlIih7gQjnYiIlIih7kiQ2FMnIiJFYqjbKL9LnT11IiJSJIa6E+yoExGREjHU7XChHBERKRdD3QlmOhERKRFD3YZQsfV701aDiIioQRjqdjj8TkREysVQd4aZTkRECsRQd0JkT52IiBSIoW5DqL0IERHRVYuhXoXE1e9ERKRIDHU75QvlOKlOREQKxFC3IQgABN6nTkREysRQd4KhTkRESsRQd4LD70REpEQMdSfYUyciIiViqNsQwH1iiYhIuRjqVUjcfIaIiBSJoW6H288QEZFyMdRtVEQ6H+hCRERKxFC3VTGlzkwnIiIFYqg7wZ46EREpEUPdhjz83qS1ICIiahiGup3yvd+Z6kREpEAMdSe4oxwRESkRQ90GH+hCRERKxlB3gqFORERKxFC3IwCQuPqdiIgUiaFug6vfiYhIyRjqzjDViYhIgRjqTnD4nYiIlIihbkMQyu9Tb+J6EBERNQRD3YEgsKdORETKxFB3gplORERKxFC3wdXvRESkZAx1Jzj8TkRESsRQt8MHuhARkXIx1G2UL36HKIlNWxEiIqIGYKjbYU+diIiUi6Fuo2KhHFfKERGREjHUnRDZVSciIgViqNsSai9CRER0tWKo27GmuoUL5YiISIEY6jY4p05ERErGUHeCmU5EREqkaegb7777buh0OgBA69atMWbMGCxcuBBqtRrR0dGYOnUqRFHEq6++ilOnTsHT0xMLFixA27ZtERcXV+eyV5K8TSwXyhERkQI1KNTLysoAAGvWrJGP3XXXXVi2bBnatGmDJ598EgkJCUhNTYXRaMSGDRsQFxeHxYsXY9WqVZg7d26dy15RAu9TJyIi5WpQqJ88eRIlJSWYOHEizGaS6TzZAAAgAElEQVQzpk2bBqPRiIiICABAdHQ0YmJikJWVhSFDhgAA+vbti2PHjkGv19e5bFOROABPREQK1KBQ9/b2xqRJk/DAAw8gKSkJTzzxBPz9/eXXfX19cfHiRej1evj5+cnH1Wp1lWM1lTWbzdBoqq9iUJAPNBp1Q34Epzw0asAI+Pl5ITRU12jnvRax/VzHNnQd27BxsB1dd6XasEGh3r59e7Rt2xaCIKB9+/bQ6XTIz8+XXzcYDPD390dpaSkMBoN8XBRF+Pn52R2rqWxNgQ4AeXnFDal+tcxmCwCgsLAUWVlFjXrua0loqI7t5yK2oevYho2D7ei6xm7Dmi4QGrT6/ZtvvsHixYsBAJmZmSgpKYGPjw8uXLgASZKwa9cuREVFoV+/fti5cycAIC4uDl26dIGfnx88PDzqVPZKUwnW5hDB+9SJiEh5GtRTv//++/HSSy9h3LhxEAQBr7/+OlQqFZ5//nlYLBZER0ejT58+6NWrF3bv3o2xY8dCkiS8/vrrAIB58+bVueyVpBE8AAAm0XTFP5uIiMhVgqTg+7cae0jonX2f46zhOIZ5P4L7boxs1HNfSzhc5zq2oevYho2D7ei6q3743V15qjwBAKXmsiauCRERUf0x1G14qa3D72UWYxPXhIiIqP4Y6ja8NNZQN5o5p05ERMrDULfhpbEOvxstDHUiIlIehroNL3V5qHP1OxERKRBD3Ya3hxcAwCRyTp2IiJSHoW5DWz78zvvUiYhIiRjqNrRyT52hTkREysNQt+Hj6Q0AMIOhTkREysNQt6HVaAEAZombzxARkfIw1G34aCp66lwoR0REysNQtyH31BnqRESkQAx1GxWhLgoMdSIiUh6Gug0PlQaQVBBVRij44XVERHSNYqjbEAQBaskTUJthNIlNXR0iIqJ6Yag70MATgtqEUqO5qatCRERULwx1Bx4qL0BjRqnR0tRVISIiqheGugMvlTcElQh9Ke9VJyIiZWGoO/BSW+9VLyjVN3FNiIiI6oeh7kBbHuqFZcVNXBMiIqL6Yag70Hr4AACKSg1NXBMiIqL6Yag78PW0bkBjMJU0cU2IiIjqh6HuQOdp7akz1ImISGkY6g503r4AgGKGOhERKQxD3YG/t7WnXmopbeKaEBER1Q9D3UGAjx8AhjoRESkPQ91BoNYa6kaRm88QEZGyMNQdBPvqAABGiaFORETKwlB3EOxr7ambGOpERKQwDHUHXhpPQBRgEYxNXRUiIqJ6Yag7EAQBED3sQr3YVIILhSlNWCsiIqLaMdSdUImekAST/P2bscuw5OD7yCnJa8JaERER1Yyh7oRa8oCkrgz1S8XZAIACY0FTVYmIiKhWDHUn1PCCoBJRbORiOSIiUg6GuhOesD7UJdtg3zOXpKaoDRERUd0w1J3wFqz7v2cV59odt0jmpqgOERFRnWiaugJXI63aeq/6p6c+hV66Wz5utJiqewsREVGTY0/dCZ3GX/564+nv5a9NInvqRER09WKoO9HKsyMsuc2rHDeJ7KkTEdHVi6HuhNZLA1NaxyrHTRx+JyKiqxhD3QlvTzWkUp8qx4117KkXm4qxO3Uf5+CJiOiKYqg7ofXUAKIGKqjtjhebivHz+W34POHrGt+/M3Uv1p3ajM8S1gEASs1lECURGYZMnMk7f9nq3dgk3sNHRKQoXP3uhI+3tVmiNf9BTsB+JOScBABsTfpDLjO26z3w1ng7fb/epAcAHM0+juySHMyNWYLhbYZi+8WdAIBltyyGSlBBlEQIEKz7zV+F3o5dCQ+VBv/t91RTV4WIiOqAPXUnAv28AAAlBg3u73yH0zLvHPoAJosJZRYjiox6u9fMogUAIEFCUsEFAJADHQBKzKUoNpVg2l8z8dXJb/DxsbXYlx5r834z1pzYiOTCi436c9VXYmEyTuefa9I6EBFR3bGn7kRFqOfryxDmE4oZ/Z+BWlDj9f3vyGVS9GnYfnEntpz/DQDwYtQ0fHPmR9zd8XZcLEqVyznrhW849R1iLx0BAMSkHwAAHL4Uj4EtrwcAHMg4jL3pB7E3/SBWDHuj2nqKkohVRz5Dj2ZdcUubaBd/aiIiUjr21J3Qeqnh6aFCQmIuTGYLInSt0cqvJZ7tNxkDW1wvl6sIdAB44+AynC9IxtJDK5FUeEE+7uzJbhWBXh3bBXnvH/4IafoMlJpLsfnMFmw5/xtKzCUAgEJjEY7nnsI3Z35s8M/qKLskF0YLnyVPRKREDHUnBEFAaIAWFlHCscTKrWI7BbbHwz3GYPktS3B3x1F1OtcP53+p8+deKEqBJEkQJVE+dirvLBbuX4qj2Sfw58V/8GvSdnwU/yUAoMzs/IEzRUY9vjy+AXml+XX+bADl8/+L8WH8F/V6H9G1rNRcBkv5lBtRU2OoV+PO6PYAgIyc4iqvCYKAEW1vxophb2DuoBfRN7QXhkcMxaSeD0EtqKuUr6slB97H8dzTOJBxuMprqfp0+euKee5ic6nT8/x58R/sy4jFqvjPcLEoFemGzDp9fobhEgDgZN4ZuwsLqtlvSX9if8ahpq4GNQFJkvDcztl2U3NETYlz6tUID7E+1GXTjnPw9FDjpr7h0KirXgOF+YTgiV4T5O+vC+2FPen7IUoiPFQeWHNiI/w8fPGfbvdj3cnNKDLpq5zD1sojnzg9fja/8la4iguH4vJheEea8tdT9elYfOA9AMDTvR9Ft6DO8FB7VPvZEipvYTPb9DwsogVqVcMvVtzdj+d/BQAMaNHP6evbL+xEsbkEd3QYeSWrRVdAxcVvRvGlJq4JkRVDvRotgrVo5u+FnMIyfPX7acSeuoTpD/SBp0fN4SYIAgaHD5S/H9QySv66d2gkckvzMHvPonrXJ7F8nj7A0x8GkwEXilKQVZItvz7zn9cw7bonUGIuRVJR1VXzH8R/joEtrsfDPcZU+xm2e9ubbb+WLFCDoe5MXe7l//bsTwDAUHdDFo5o0VWGoV4NtUqFOY/2x3/f3wUAOHkhH78fvIjbb2jn0nmDvYPk+9QLygrx7dmfMKTVDfBWe+FIdgK2Jv5e7XtVggqdgzrgYGYclhx43+61IpMem07/gDP51W9uE599vMoxi2iBCAkeKo28AA8A9qTvl782i2bklebD18MHS2NXonuzrniwy131+bHdlkXiXOq1jI9jpqtNg0LdZDJh1qxZSE1NhdFoxOTJk9GiRQs8/fTTaNeuHQBg3LhxGDVqFJYvX44dO3ZAo9Fg1qxZ6N27N5KTkzFz5kwIgoDOnTtj7ty5UKlUTss2JZ2PJ0bf2BYXM/U4ci4H/xxJx6hBbV3eLEYlWIfxA7z88VjkePl4a104egR3hdFixJHsY7hQmILrwnrLPb3b2g5D92ZdcTAzzul5awp0ACgxl+DjY2txf+c7EOgVAMC6aj9Fn4YVw95Aic0c/Xdnf5a/NpiKMX/fWxAgQIKESynZVzzUS8ylSNWno1Nge5fOYxbN+OviLvRvcZ3cBq6ej65dFpE9dbq6NCjUf/zxRwQGBuLNN99EXl4e7rnnHkyZMgWPPfYYJk6cKJdLSEjA/v37sWnTJqSnp2PatGnYvHkzFi1ahOnTp2PgwIGYM2cOtm/fjvDwcKdlm9q9QztCFCU8/sZfuJRfgrmf7sf/3dMLLYKr7g3fGNoHRAAAugZ3ko8NDh+INEM62vtbLyie7TcZWxN/x6m8s/U+/+FL8Th8KR7/6XY/is0lSNGnAQA+T/ga/l46p+8pNBYBsJ9zbyx/XPgbp/PO4enej8oXO858lrAOCTknMbXv4+ge3KXacsWmYmg12movvP5J3Yvvz23F4ayjeDFqmsv1N9dj1bMoiTX+jKQ8HKmhq02DQv22227DyJGV84NqtRrHjh1DYmIitm/fjrZt22LWrFmIjY1FdHQ0BEFAeHg4LBYLcnNzkZCQgAEDBgAAhg4dit27d6N9+/ZOywYHBzfOT+oClaoyIFKyDHhr/WG8OO46hAVdnmB35K3xQoeAdvL3nQLb45nrnpS/T9NnwCyakZBzEoezjqJXSA/ojXrsSttX7Tm/OvmN3fcHMquuuK+gN9a8uM9WfFYCgkx+aOPRttayJtEsjwgUm0vg5+FbpUxOSS681F7yVr1n8xOrDfV0QyYW7HsbN7UeXO1IQl6Z9Ta/NJu7CVxhrmX41XbO3Sxa4OlksSUp1+UO9bzSfFgkC0K0zS7r55D7aFCo+/pa//jq9Xo888wzmD59OoxGIx544AH07NkTq1atwooVK6DT6RAYGGj3vqKiIkiSJPekKo7p9XqnZWsK9aAgH2g0jb+AKzS0ao91ydRozPt4L4pLzcgtLMMbXx/GbYPa4fTFfLQK9cOkOyObbA/3ivpe37E7HsY9AKz3zgoHJfyTvB89Qjujd4vuaOXfAm/v/qje55e8qj5tzksH+HtXbacP/7Te4z5zyP9hc8JWXDLkYNntr8Hbo+o++RlFlSuG/7m0Gze2uR6dmrWD0WLCwdR4DGzdF1M2vQgvtSd0Xn4oKtOjTChx+vsBgMMF1tvK/k7ZjSmDH3JaxifV0/qFIFR7nvoQ9ZVTFs7OZ/ukvsBgb/h61v1CsOJ8+jIDXt7+Bh7sORqDI/q7UNtrT2P8jmtiKapch3I5PmvKhhcBABvHrGr0c9fH5W7Ha8GVasMGL5RLT0/HlClTMH78eNxxxx0oLCyEv78/AGDEiBGYP38+hg8fDoPBIL/HYDBAp9NBpVLZHfP394efn5/TsjXJy6t6D7mrQkN1yMoqqnrczxPLpw+FRRTx+S8nsftoBtZtOwUAOHgiE73aBcFXq0HzIB98uvUEyowWTL67JwDgXFoBDCUm9O4Y0uj1rcmYDvdhQEgU2urayLekjWo/osbFeD2bdYO/p7/dQrm0nOwq5V75423MHvic/P3J3DPyrV0AsPiflfLXh5NOO50LTy3Kkb/+6dQf+OnUH1gx7A2sO/kNdqftx/CIoQCAMosRzX3CUFSmx54LB3FvuzudDmPr9ZWb8fyWsBsdA9ohwMvfrkxxcflueRKc/p7r65KhQP7a2fmKTZX/RjOy8uHvWbeene2/w79T9iC96BLei/kUXbTdXKxxzUrMJSizGBtlvUFTq+7/5caUZSis/Poyftbl/jlqciXa0d01dhvWdIHQoLHA7OxsTJw4ES+88ALuv/9+AMCkSZMQHx8PAIiJiUFkZCT69euHXbt2QRRFpKWlQRRFBAcHo0ePHti3zzo0vHPnTkRFRVVb9mqjVqkw4dauaNfCvlEXfHkQL324Fxv/PItd8ek4cPISSsqsQ7MLv4zFu5viYTJf2UU1giCgQ0A7u3vMR7X7F/7dbjg6BLTFQ90eqPKeMosRfp72w+C/Jv9ZpVyGIRMW0YKDmXEwiWZ8GP95tQ+gMZVve5tfVoCDNhvrlFazec7Z/EQAQEL2SfmYj0Yr169ijr+qypGST46txduxK6qUaOi6AEmSoDcaqhw32cypO9uwx3bL34YsqhMl8YpubPPSrvl4effCK/Z5rjCYipt8kyTe0nbtOZp9HJvPbLlqH03doJ76Bx98gMLCQqxcuRIrV1p7ZDNnzsTrr78ODw8PhISEYP78+fDz80NUVBTGjBkDURQxZ84cAMCMGTMwe/ZsLF26FB06dMDIkSOhVqudlr0aeXqoMWvC9Th1IR9nUvIRk5CBrHxrQP26v3Lf91U/HEOwrnLY+VxqAbq1DbI7V0ZuMcICtXbz9peTIAgY3WEkRsO6JuK6sF7wUHngdN45LD/yMW5rNxwh2mbYlvyX/J7q/nA+s+MlAMBt7YbDU+1pF2C2csv3v3/n0AfILsmBv5cOQV5BKKxlrt42vMts9qP/6uQ3mNJnkpN32P9PllNadd/9CvVt7e0Xd+K7sz/jv9c9iS5BlYsYbYPa4mQhnO3we0NC/cvjG+VnCWiredRvfZksJqhVarmuttNhFXsVXO0bDhUai/DSrvno2aw7Jvd5rMnqcTm3h7V9tsTV/vtoDBbRgvyyQjTTBlVbptRcihVHPsWtbW9Gr5AeV7B2lT6I/xwAMKzNEAR5B9ZcuAk0KNRfeeUVvPLKK1WOr1+/vsqxadOmYdo0+1XG7du3x9q1a+tU9mqlUasQ2T4Yke2Dccfgdvj27/OQAMSdyUZGrnXI9dj5XLv3vL0hDh1bBeDhkV0RHuKLw6ezsOzbo7jvpg7y/e+SJCGvqAzB/o3zB7w2Fc+E796sC96/eZH8h+PeTqPlW+lq82vS9hpfX3dqMwa3GojsEutw+7n8ZPyUWP3cfkVv2nbHvBJLZa/+eM4pmCwmeXe82Mw4xGYeQbvyOwcuh1+TrKMVhy8dRUvfFkg3ZKBLUCe7oP41aTtEScR1ob0Q4d8aQOUoBWBdKPfl8Q0I92uBf0XcZHf+/LICCBCqTBccyKzspXupvVz+OUrMJXh+51xENe+LxyLHwyJa8MyOl9A3tJfdzogm0eRSiGQYMvHnxX9wX+c74aX2dLnegPViJD47Ab1CIpFVbP23dCznRIPPV2gsgiQBAdXc9WFLlER8deIb9Artgb6hPeXj5su0UC6vNN/u/yujaILWTUI9VZ+OM3nncXObwXbH15/6FnvSD+DFqGlo69/G6XsPXzqK8wVJ+CD+8xqfYNkQeqMBEiToPP3qVD65KMV9Qp3sqVUqPHCLtfc2alBbrN9+BsWlZhjNFhxPquwtWkQJpy/m47XPD2Dp1MHYddS6AnvLniT4aj0Q1TUMB09dwpe/nsIz9/VG385Xdg7e9o/4sDZD0MI3DB0D2uFM/nl0CuwAT5UHkotSsP3CTsRlHQUAtPAJq9MWmb8lVQ7hn8o7U205vdGAS8VV5/ALygrtvv/9wg50CeqEToHt8WnCOgCodqRAlEQUm0rg5+lbOfwuCHIvS61SQ5Ik7E0/iG7Bne3+RxUlEZ8e+0remOdIVgJ2psYAAF4e8D+71e8Vf4S3Jf8l/8GxDfVicwn2ZcQCsO40aLvav2LIuy5/qC4UpmDJwffRL6w3Jkb+p14LNCv29z+YGYfHIsfL2xZX/D4rGEUTvNHwC8sVRz5FbmkeQrUhGNH2Zqdl5u97Gy19m+Pxns4XNTr6OfF3/H5hB4a3GYrrwno1qF67U/ehY2A7tPBtjpd2zbfWtQ5tnqpPx96Mg9ibYf845MvVUzc5/Fs2iSZoXfh9NIU/L+zEidwzmNznMbsRrIp98tsFtEE7/8oL8T3lj6E+V5BUJdTzSvOxcP87aKtr3ej11BsN2JtxUL4Tp64XC6uPfoknez2CPqGRjV4nVzDUG5mf1gOPj7YfFjp1IQ+CIGD1luPIKSyF0Sxi6rv/yK8bTSK+/PUU4s5k40yKdeHVF7+dhNYrEhHNddB6XflfkyAIiGxmXZRlO8zVIaAtOvSagL3pBxHsHYgWvs0xe8+iKkPLvUJ64KjNDna2i+hq2iRnxq55To+XmEsQ5BWIezqNwqcJ6/Bz4u/4OfF3hPu2kMtkObkYSClKw6ID7wIAnrv+/+y2wl0Wtxol5lKMbDcMJosJa09uQnOfMMwZ9Lxc5mJRKg7bBF6BsfLi4t1DH6BbcGen9b1UnI11J7+x+1lte14z/pmHR3qMxYAW/eo9N7f0kHXK69CleNzf+a469TQBYNPpH7AjZbfdsfyyAqdlP4z/AtOve0oeDckuycXiA+/hkR5j6jTsWXHe6tZNiJKIDEMmMur4sCEA8jREUuFF9K7nH9IjWcdwMDMOhy5Z1/28e1P91g04hmwF21va6rMPgVk0Q4BQ7WiI7bQNYP13mJBzEq18W2Jwq4FO33O5xKYdhdEg1Xvjp83lI316kwH+nlX/jZaYnP/bcJRZnIWfz29DibkEJ2voECQXXkSKPs1um+66+OjoFzhXkGR3rMiox8WiVPRo1lU+FpN2AB0D29mVO5t/nqF+LeoaYZ0jWjL5Bvx1KBVf/X7aabn4c5WrwQv0RixZZ11U9uAtnXDbwAhYRBHf/n0evTs2k8/ZVGz3tH/npgU4X5AMT7UHfDRamDxL0FwVjqTCC1AJKuy4uLvG++DrytfDB639wu2OpRky5K+zS3Md3yIHOgC8HVu5It9oMcqB+8mxyqmgzPJRh4o/0G8cXFZtfQzmYsReOuL0tXl7q17tn8i1/71/cXw9LKIFfcMqh3MlSUJOaR7Op5xFG492duUreoW2FyYGk6FOoZ5YkFwl0AEg32EEpEJS4QWcLajcE+DvlN0oMZfgk2NrsSh6DiRJhI+HT3kdinEg8zAGtbhens6piUk0N6iHK5Zf/KgEwW6NRV18dPRLu+/nxiyu1/ttPy+7JAep+gz0CY20WyhXl30Iiox6JOScxJoTG9Hevy3Gd7sPBzIP444OI+ULgj8u/G23oyMArDzyqfz14FYDsS89FmmGDNzT6XYA1n+v+zIOoW9oJLTli0obg0W0YEn5nSzv3fw60g2ZCPdtgTRDJtL06egV0gM+HjV/nt7oPNSXH/kYcwe9iDCfmkckX9v7Zo2vm0UzLJIo/7/aOySyxiH0/LICaFQaeaQsuSjF7nWTaMabB5cjpzQXQ1vdgHs7jUZ6cSbWntxUYz2uFgz1K0glCBh+fWtc1zkE2QWl8NN6QKNRwUujwrHEXHy61To/2L9bGPafqBzS3vjXWWzdmwx9ifXqffuhFHzw3M0oLDai1GhBUnohykwWNA/yQZc2V36ORyWo7K7iK27fqNgw59HICDwaOQ4l5hJ4q71hEk0wmIpxJv88vNSe8PXwRfvyYbijOSdQWFaEIO8AeUGKVuMt96jDfELR0rd5nR8n2xBT/nzxsp3b0dqTm/DHxZ3y9wZzMV7b+yYskgUPdLbfQKfUUlZl5b++lqf+AdY/zG85uRMAsO+pOy6INItmZJfkQufpJw/xS5KEOXsWodhcguW3LMHMXa9Bb7LeFRCTdgAz+//XbjrgYGYcbokYIv8BPZp9HB/Ef+70zouK85/IPY1PE9ZhYIt+GNluGPJK81FiLrW7c8FUj1B3ttCzwKYdTaIZHqqa/xTa3pq4NHYlCoxFmNn/v7DYLZS0AKj+KYiAdd44LusYACCxMBlvx65AqaUMrfxaIqp5XwCoEujOfHliAwDrIlWtxhu7Uvdiw+nvEXepcRYOFpQVwWgx2k0vbTr9A3al7UNzn1BkFmcBANroWuG566fg8KV4XB/Wx+nIQ6o+HWUWo7xbpq3vzv6Mp3o/YnfsQmEKZv7zGqJbDcToGh6ClGHIREFZEX5J+qPKiFiwdxDa6FqhS1BHu/dIkoSXdy+ERqXBeze/jnP5SVVGGUvMJcgp7yDsTI2Rp9tqk1OSi9hLR3Ai9wy6BXXCyHbD6vS+xsZQbwLB/t5VFsIN7tUSPdoFQxCAAF9PRHUNQ7C/NxLTC/HV76flQAesw/UTF1e9zQwAPp3ZNP+Q6qKiB+Gp9oSn2tPpo0ptFyH1CYlEZkk2nus3GSXmMnlV7NO9H0OGIRORzbrJATJ9xyyYRDMe6HwXNp35AQDQ3j8CHQLa4frmffD58a8hQICPRis/8e6JXg/DYDRg3amGb0d8W7vhtS4UrI3tEPSMfyqnHyp+jgom0YSlNqMN1vdmwSKKaOnXHAIE+HvqIAgCckpycSrvLG5o2R+p1eyeV2TU261VKLOU2b2eUpSOD+I/R5egTvJcplmywFy+vmBX2j450AEgRZ+GhJyT6BnSXT6WXZqLt2NXoH/z61Bk1Mt/IDef3SKX2ZkSg0Avf1gkEV+f2gxDeYDuSNmNE7ln5NGT9v7WXQpzS/Ox+tga+f2XirOr9PaKjHr8dOgXtPfpgDBtzT3BMnMZPDxr/lNoMFUu2qy4IDhfkGzXA3XcXU6URBQZ7UdSzhck25UpLW/zzxLWQavR4tNjVRcQO7K9SEnVpyMm/QAKy6x1SixMRpnFCEkS6zRqUp05MdYptWiboeyKHSorAh2wTgtM3zELAHAm7zyGtB6ECId578+Pfw0AeLDL3QjR2t+mHJ+dgHP5SXa/v4pRvV+StuNIVkK1dZy/722nx21HpB7vOcFu/UXF4luzaMal4ix5KstWdVNSzvx58R/EpB/EjeH9sf1C5cX56byziPBvDW+1t9OLmctJkK7Wm+3q4HJsiHC1bbRgMotYu+0U/olPh1ol4J6hHfDNjnPVlr/vpg4YOSACb62PQ3iIL8YN74zM3GK0DqscjkrKKESArxeCdK6vpnamKdqwoKwQFsmCIK9ApBkyEO7botoFZGUWI0RJlG8RyyrOwe8XdiA6fCCOZCcgyCsAZsmC35L+hNFiQqmlFGpBjYk9/4M2fuH48fyvOJgZh8m9H0PPkO74PXkHvj+3tcrn3NhyAEK0wXbrCWz1b94PBzMPN+qe+je07I9j2SfkBXCPRY7Hufwk7EzdU6WsAAE9Q7rLax98NT4wmJ1v6PSviJvwx4W/a/38YW2G4O6Oo+TbHeujT2hPHCnvxTrT3CdMDnhHodpmaOcfgUd6jMXPidtwviAZp/LOwlvthad7P4p3D39Y7Xn/r88k7EzZjf90f8DpMDEA/JK4HT8l/mZ3bHD4AHQK7IAvjlvv+nl98Gz4emjx54V/EOgdgCKjHt+e/QkPdx+DHs264tuzPzXKngPdgjrLc8t+Hr52F1a2Vgx7A3FZxxDkFSAvPEsuvIidKTF4oMtd8NZU//+/K6NV79+8CCpBhal/zajzezSC+rLdSaDz8ENLvxbQarxr/Pd1uXQO7ID5I55DTo7z31ND1LT5DEPdwdUW6s5s+PMMMnNLoPXSICYho8ayQ/uEY+eRNDx1ZyROXcwHJAk74tLg7+OBd58Zclnqp4Q2rA/b+7idqeiRiZIFKkEFCRLySvPRPqCt/P5SSymMFjOMFiOOZifg+uZ9EeDlj9jMI/g1abvd2oBr1XWhvewWJTryUnvWOpce1bxvlacY9g3tKQ9516RPSCSyS3PRwicM/p46NPcNRUYOm4oAAB9uSURBVHb5iEdKUZp88VUxHeRoQIt+0Hn4YbvNdEpTsv25Owa0R2Jhsl0vf94NMxCibYaTuWdgMBkACPjp/G9opg2usv6jvka3vxU/JW5z6Rzu5I1bX4avufF2aWSo14OSAqnMZMGRs9nw8dIgyN8bsz+u/gEuzix4fCB8tR4I8K16H/Ffh1Pxd1wqpt7TCyGB9Vt4o6Q2vFrklxVgf/ohqFVq9AmNhIcvMOuPJejf/Dq0D2gLrcYbR7OPwyKJGNPlbug8/TDtr5kArGHXIaBdtX+Ig7wC0S+s92UNmw4BbasMLdPVTavRYu6gFzBz12tNXRUA1umw5j6h2Hjqe5zOtx+NrGlEojE81esR5JcVYsPp7+pU3nFUq5VfS/hqfFBgLIQoicgqybErP3Xgo+ju23ib5TDU60HJgZSUUQh9iQlJ6UU4dDoLSRm1/xwBfp54Z2q03bEyowWTl1YOtX4y4xYUlZiQlVeCjq1qv9pUchteLerShqn6dKgEFVr6NpePFZuK4aX2gkk0w2Cy3vPfLbgzBEFAibkE6099h9vb34oQbTCO55xCXlkBOgW2R4m5FPllBYjPSkBCzkmEaJvhgsOq4Bta9ke4XwsczIxDz2bdsC89FsMjbsI/qTH43/WTcSQrAWtObAQABHjqUGAsQrB3EHJtdva7PqxPtXcMOGrmHSwvWLratNG1wsWi1Hq/74Eud2HTafu1Ere2vUXewbFHs65o7ReOs/nna71I6hHcFcdzT9W7DrVp5x+BlKJU3N7+Vvxw/he712b2/y+2Jf8l3xrojHV1vHXk6caWA3A89xQ6BrRDM20wCsuKkFF8CYPDB6KNLhyLD7wHAJh/40sI9q68o8csmnEq7yzisxKwK20fhra6AdeF9cJnCV/Li0VtP2dw+ECoBTUOXTqCUG0IxnW7F2fzE/HT+d8wtPWNuLFlf/yc+Dvu7HgbTuedk6dMANjtEqk3GvD58a/RM6Q7Np3+AQNa9INWo8XfKbvRO8T60K52uja4td0tKDWXQiWokFx4EZ0CO8ijefllBVi8/z0IgoBHe4zD2YJE3NfnVpQWNl7UMtTrwZ0CaffRdMSeykLc2ar3b9u6bWAEboxsgdZhfjiRnIe3vj5sN8v72sQBWP7tUVzKL8Hip29AWC09d3dqw6ZyNbRhbdMOzuSXFUAtqO1uKTqS9f/t3Xl8VOX1+PHPLNn3PSQhG0mAgOyyySoWQcWFKhVa1NqfitXi2kq1fGtbtFXp7+XWurQ/bd3FffmqgCyGsBMIEJaEhKyTQCZ7ZjKTWe79/TFkQphEEoIkxPP+L5mZO5fDZM69z3Oe8+SRa8zjZxk34Kv34dPCr1hfthkAnUbH4qEL+fz4NzTZmkkPTSXaP5I5g2cQ6RfBym1/Jdw3lGHhGXxd8q37mE9c9hjGlhoi/MJZue2vAEwddCk3pF2NXqun2WbGP1jHw2tXAa67UovDQlLQYIaEJhPjH0WkXwSlTeWd1jzE+EfjUBx467w8VlqMjhzBkuE3smLLnxkWnk5mxFBXc5qqPR7H+UniLPbX5LkbKv1pygr3crqfZVxPi8PCnMSZrNr5d2ostSxInce8U1XTq/e8SHFTGctG3caIiGEYTCdobG3knaMfctuIJQwJScZoqSXXmMcXXdRtAMxMmMqN6dfyWt7b7DMeJD5wEE7F2aFp1KTY8RQ3lXLnJbcyKCDGvaSzydZMg6aWf+z4L/OS5zB78DRUVeXlA69Tbalh2SW3EeQdxFtH1jA4KIH5KXNQVZXVOf8g2DvIo7L9TLnGPOqs9Vw+uPOpQKfiZEfVHi6JynTXO5hsZhyqg8O1Bbx99AOuTLqca4fMcz/fqSp467pehVDcWMbqnBcB+P2l95MQFNfp8+qtDQR5B6LVaDlSd4yhYUPQn2WVRFcu5IYuktTP0B++TM+3VpsTi82BBvDz0ZNbWMPLn3WsKtVo4OopSXy5zfPu4PJx8Wzc67orefjmMWQmf/9GO6fHsMVqx89H32fb0l6sBuLnsI1DcdBsMxHiE+xem21xWGmxWzz6ftucdvSn+tTn1xUSGxCDv5dfhyVo60o2kRqa7NEcJSoqiMOlJdS31pMWmupRid7maN0x7IqdzPChaDQarA6rew1+27kVNRTjUJ2oququpm512tBptO4veovDwsGaIwwNS0dRnTTZmt0FalaHFZPdTKRfBJ8XfUONpZbbR/7c/R7lzZVkG7ZzQ9o17gK2Wks9VeYTHVYTdKat9W+IdzC3j/w5TsXJoMAY1pduptlm5rYRN7vjXtJUTmpIElqNljprPTkn92NX7MxLntNl45xz/Syey0VhT49/vLGUlJDEbjf9aXvdhvIshodnEB846Ac7v9NJUu8mSernRlVV9h2rQaOBN9bm02jqWSOP66enkB4fQlSoX6fz7VFRQVRXN7F+TwXvbzjG4ivSmTM+gbKTJhJjAvs8wbfanBw4XsuEoVF9fi5d+TF8Dn9oP6YYWh2teGn1P8imLz+mOP5QLmRSl3XqP0IajYZxGVEAjE2P4mRdC//8NI+hg0Px0msZmRLOM+/lMmd8AkdK66ms6Vig8ukW19aoCVGB3HltJv4+eoL8vfHSa6mub+HTrSXYWh3uHeu25Z3A4VRZs6mQuZcOZtHsNHYeOUlGQigRIa5lZTa7E0urg5DAH2aZ3ele//oIu45U84u5GVw+7vz3khbiQvu+5Wnix0Xu1M8gV6UuDqeCTqvBZldoNLfiVFT+/eVhiquaCfb3oqmlY2/qyFPJuaaxe/2cAaZdMojbr3YNLT77wX4OFNXy/H3TCfRrnw9zKgpmq4Ngf1eFfqvNyfFK1xa233eX/X1Df8uf24LJYmfWmDhumTes2+d7IZ35OSw72UxMmD8+3gNjp64LQf6Wzw+JY+/Jnbroc/pTPax9vHVEe7vmF/9wywRqm6xEhviRk1/NPz5pX/vbk2TeJvtgFfuOGTFb29s0vrUun/mTkrA7FEICvflmZxmb9hncBXrvbjhG1v5KfnX1cCKCfSmoaGDB1OQOCbypxcbKf+9k3sRE5k9O8njftqdeLFezhhozj7++m2GJofxuiWcXPiGEaCNJXXSbRqMhMsQ1hz4mPZJrpiYTE+bH5lwDRQbPjUF+OX8YWQcqO32szekJHWDXkeoOfe/brHh5O0kxQZSedF3tbj90wr2t7YacCqJD/bh+eipbD1ax47CrWvmDzUVcOSmRQ8V1fPRdEQ8sGkOwvxfNp0YZvsutJCzIh2svcxVY5eRXU9No5cqJ3WvreOYowg+lrsl1wXS0rIH1e8oZmRLOoIiAs7xKCPFjJEldnBOdVsvCGamAq2+91eZAr9Oi12mJigqi3FCPj5eOjMRQXvjoIIPC/blyYiJ+Pjpe/uwQ9c2ttLQ6zvIuHbUldKDDPvXNLXaaW+z8/f1cj9d8ubWET7NdNQAbcspJiOq4e9OnW4pRFJXJI2LdIw+zxsbj49X5MLdTUcgva2B4UhhrNhaxfk85s8fFs2mvgYduHsPwpDC0p4YCrDYHvmfpKd4drbb29pnvfutqD9rdHv9ts2sajYZGUyuvfnGYm+ekMzi6612shBAXL5lTP4PMH/Ved2LYaLZhstiJjwyg5EQTidFBPPfhAewOJz+7PJ11u8vYfshzJ7Zb5w2lrNrEpr09b/wBrs1yGs0dq/11Wg1Opf3P4LGl4zE2WkiLCyEy1I8TdS3kHqvB31fP8comsvZXcueCTF794vCZh+e2+cOYMTqOimoT//PaLiKCffnprFQmZ8aiqiqVtS3ER579Lvv0GG7ONfDGNx2bjHQ3qT/5Zg6Bfl4sv3EUr/3vEbIPVpEQFciffzWxW6+/mA2Uv2WD0cTRsgbmjO+bos6BEse+JHPqYsALCfB2t6dNjg0G4IFFo92P37FgBNdMTcZqc5IcG8TnW0uICvVl6shB2B0Kg6MDcTgURg2J4KXPDuFwKBhOVenPm5iIyWIn+6Dn7mRnJvSIYB9qmzruTvbEmzlnPf/OEjrA/sIaZoyOY/dR1xRCbZOVVz8/zKufH2bepES+2VnGkivSuWKCa/2yw6lwvNI1PXH6trn7C4z89b+7+N2ScZjOKEoEKChvIDEm8HtHAuwOhUKDa8cpg9FEc4vr366c5TreqSiYLI5O2wf3d4dL6lj9Xi6PLh3/vV98F5OV/28XAKlxwaQMCu7jsxH9nSR10W+dPm983bT2xiJeei2zxsS7f/7jbZcCkF9Wz75jNSycmUqL1YFGAwumJvPuhmNEBPui1WooKG9g8ohYMgaHUFjRyOQRsSx/bss5n+OoIREcKGrv83zweF2X2+J+s9O1xO+db4+x5UAV4UE+HCmrx2Z3bbLx/H3T8ffVY7bY+dsbuzFbHfzxtV1MzozxONbf3t5LoJ8Xzy6fhlajwdLqoLreQlJseyJrS+IAr3x+iAqj66KnssZM6YnmDs893XvfFrJhbwV//tVEj+mK3rI7FPbkVzNxeDQ6bfcbhnSHw6m4p1reWV/AlDEX5s52x+ETrNtVzu+WjD0v0y1dsdp+mF3MxMAiw+9nkKGm3rvYYtg2vD57bDzlRhN1TVZO1LYQHeZHs8XOmo2FqKorgceE+xEe7MvHWccJ8ffmybsmY2118vjru85pBcD5sGh2GruPVlNc1cQDi0YzIiWc4qom9hytZu2u8i5f9+pvZ5GTb6TB1EqL1cFll8RitTl5/PXdAFw1OQmtVsOYtEjiIv35OOs400fFUd9s5dkPDrBwRirXTE0GXAl17a4yRg+J7LDNL7gKGbMPVvHwzWP4dEsxG3IquH56iqt7W6uDQkMjE4fHdGt4udXmRKfTuJZbOhR37cPmfQbeWJtPalwwxyub8PPRs+bJq92fQ2ODBUVRiQn3/77Dn5PTL+L+8n8mER8ZcF67qbUdvzvdHH8I/e3v2eFUyMk3Mn5olHuVTn8nHeW6SZJ6/zTQYnh6sVkbu8OJotKhoK6gvIH/fnMUL72Wy8clkJkcRmVNC8MSQ6lrbuXDzUXMHhvPO98WUFXbvsOTv4++x0WDXYkM8b2gFxdPLZvC51uL2XrQtbFGWkIIS65I53hlE1/vKOP+RaPduwdePy3FfSedmRzWodgRXHUCR0vrOVbRwMwx8RgbLQyJa99AyKko3PH0ZjKTwxg/NJo31+azYGoyN8xI9Rgd0Wo0fLb6WozGZhrNNh54IRsfLx333zSKfcdquGpKErWNVmoarT3qLGh3ONHrtJgsdjbkVHDV5CSW/b1986PM5DAMRjMRIb784ZYJ3TpebVMrsV1cbDS12Lj/+WwApoyIobaplftuHIWfz4UbZO1vf8/vbzzG2l3lXD0liZ/OHNLXp9MtMqcuRD/S2Re+l96zOj5jcChP3DG5w+/algDGhvtz70JXz/A/3DIBq82Jze6kqLKRselR5OQbOV7ZyObcSvdrF89Jx0uv5Y21+cweF8/BolpuuXIo3l46vtpRyg3TU3nqnb0dhmW7k9DnT0pk68EqjwZC5+KRl7d3+LmwopE//6d9Y5PTtwNuS+iAR0IHaDC18vS7+wD45FTXwvFDo1g8J50AXy+Kq5rcrzU2WAD4YlsJk0d4Tk8oqopyqvix0mgCXFsVP/WO6/iVNWYqa83UNbUyMjWc5T8d1eVdX5GhkQ83F6GoKscqGll23Qi25Z3gQFEtdqfS4blarYZGs82jdqMzOflGXv3iEHaHwu8Wj2VYkqvvfUF5AyUnmpl76WD+/l77io62wtHcwhqmjIj1OF7b0sfwYN+zvnd3bT90gsmjdFyoZsrGBgvBAd5drj4BOFbhqhNp+zz0JbPVjqrSoWFWG2ODhZ2HT3LVFM9eGT8kSepCXGB+Pnr3nVbbcPC0UYOYNmoQv5g7FEVVCQjyw2K2otVomDU23uMYbUV1L94/g11HTzIqNZJjFQ18ll1MSlwwC6YmU9/s6gQY5O/FB5uK2FtgBOCm2WncMCOV1e/lUlDeAMAzd0/lxU8OUtrFdr2LT9197zzcviJhTFpkhx0AhyWGcrSs4Zzj8uCLWz1+l5NvJCffiFajIdCv/evK2NB+8fLYv3Z6vA7gw43HGJ0SxjPveS51PF7Z5B4dyTtex/sbCll0eRoOp8If/r2T+uZWVvx8HLER/jz/0QF3bwOAvQVGdx2Fsd7S4bgOR3uS33qwio+zjnPtZcnMHBPvnqI4XFJPVKgvWfvbCzmzD1YxLCkMm93J397eC8DoIRGUV5s8zr2mwYLJYsffV+9ePgnw8D+3AZ4rIxxOhV1HTjJxeEyPhquPlNbzry8O89nWEv52Z8eL1er6FooMTYxJjzxvowa1jVYeeXk7QweHMm3UIJrMNq6cmIhGA05F5ZMtrumftpUqWq2GE3UteOu13bqQ6WzErU1xVRPhQT49blP9m2dd9TidrUb561s5NJhsRIb4siD6whU4yvD7GfrbUNPFSGLYe+c7hqqq8uW2EkakRJAa1/4Fk5NvxGZ3MmVkLHaHQr2ple9yDYQG+rjnLn8xN4Pk2GBUVSX7QBVvrS9g2XUjGJsexYGiGr7dU8F101JIjQvmta+OUHKiGYPR7F4qOCQumMdumUCT2caJuhZsdif/d0339lTvrZBA7+/dsOj7LkSiQ/0wNlroyTdkWJAP9c2tHr+/bloKWq2GT7KOd/najMGh7ossgFvmDfVYythGA8wYE8fY9EhKTzSj12v5YFMRAK88PIsWq53yahMjUyN4e10BG/ZWMHtsPBVGE3aHwvihUVw1OYmyk66LhmaLjRc/PshjSye4exhs3FvBW+sKAFfSUlWVzbmVBPl58c9PXT0dJmXGcNe1I9zn5VQUdwGkoqrsK6hh1JBwvPQ6Wqx2/H1dd7Rmqx0/bz1oXFMlVpuD1e/luleCnG7W2HhSBgXx+ldHCT61aqa82kRafAiFhkaCA7x59jfTaG6x8fJnh1g0O82jCLTR1Mpj/9pJalwwD/5sDPll9cSE+/PlthLSEkJ49fPD+HjreOnBmYCrLXOgn9dZLxbapn3+/cjsDhdYpz+2+Ip0lszPlDn17pCk3j9JDHvvYo9h2+oDL73rC/7MO8QjpfXUNVlJjQumvrmV8GBfDhbV0myx0WCy4aXT8vO5GXy7u5y4qAC+3lFGQXkDo4ZEsO+Ya3Tg/ptGUVDeyFc7SvH11rmnIe5ckMn6PRUew7MJUYFUGDve+T6waDQff3e8Q2Ojrrz00EzuPm3+vL9KjA6k7NQd/hN3TOIv/93TaeV8W9MkAG8vLTa7a4nonQsy8fbS8da6ArL2u6aDfrPwEnYfrXZ3azzds7+ZxmfZxdidCtkHqogM8eWJOybz9/ddI0FzLx1MfGQAr399FICFM1L5+NTFTdtFwSdZx/liW0mX/6ZFs9NYs6mwy8cfvnkM+WUNfLGthABfPb9dPBanopIyKJh1u8p4b2P7a5+4Y1KXozu//8U4kmODuWv1ZsBVTPrut8eYlBnjHh1TVJWdh08yOCqQ/3nNtdywbc+KphYbu49U8+X2EvfF5OI56Sy5SpJ6t0hS758khr0nMexIUVSaW2wE+ntxuKQeRVEZnRYJuHb402g0ZO2vJDEmkPSEUBrNNhosDnA4CfL34uDxWqaPiqOu2UpljZlnPzjAtZclc/30VEwWO5v2Gdx30TNGDyI+MpB1u8tIjg0mp8DIFeMTWPKTDDbkVPDhd0VcPTmJsCAfyk6aMNSY+OX84fzz04MUV7n+zwZHB3Y6dH4uFs1Oo8jQSHiwLz7eWr7cVkpcZIDH7on9iVajOWs/hDbLrhvBy58d6vV7pgwKcse/zdN3T+F3L3Ws+0hPCHHPy3dm8ogYdpyqX4gJ8+PkqSmWSZkx3Hx5GvsKazxGUDIGhzI5M4a31xd0aGQFrgLRX90wSpJ6d0hS758khr0nMey9nsawssZMq93p0eDF0urA20t71nX1LVYHlTVmjI0WxmVEsWmvAa0GBscEkRYfzPZDJ7HZXXfMqgrDk8J4Y10+S+cOJSzIh91Hq8kvq+fOa0ewblc5azYVcvf1I7l0WHSH92m1O9EAX+0o5fOtJcSE+ZEQFUjOqZqJzlwzNZnN+wyoqsrtVw3n9a+PYrL0vFDy9OmMX141jNe/Otrh8bYh8QtleFIYR0o9iy7bnNktsi9cPi6eB34+QZJ6d0hS758khr0nMey9izmGiqpSXW/pcqkbuBr5GBssxJ3WdthQYyYkwBu9ToPV5qTF6iAsyAc/Hz12h4LdoeDv6ypsU1WVmkYrn2cXoz+1DDMq1Jd/fppHaKAPP505BL1Og3+AL4rdjsOh4uOtY/fRahRFZdKppkjf7CzDbLVzw/RUtFoNX+8sdc/v3zAj1T0CcsWEBL7dU+E+14yEEApOu2OODfdnUmYMLVYHs8bG8e2eCjbta28HPWdcAhv2ul6fHBvEyNQIFs5IRVVV3t9YyLrdXfdkuPv6keQeqyE82IfN+wzujaROv7u/54ZL+McnB7vxv9Pu9KmENmPTIzlUXIftVNFkTLg/r6yYQ13d+RtZkaTeAxfzF0F/ITHsPYlh70kMz49ziaOhxkxchOuC5HhVE7Hh/gScKpIrrmqirsnK+KHRfJdroLzaxE2z0vDx9lzGpqgqTqeCXqdFo9FgdyiYLHbCgjyr1L/ZWUZecS1xEQHu1QEb9xoYmx7JvQsvcVe9O5wKe45W4+OlY1BkAE+9vZdxQ6P4xU8yuO/5bPcIxksPzWT97nL0Oi0lJ5q4Zkqyew59zrgEFl0+BJ1Oy5qNhTS32DHUmFgwNZnxQ6P53+0lfPRde7JfceulZAw6f22LJan3gHwR9J7EsPckhr0nMTw/LtY4KoqKzeHsUetep6LwxdYSpo6MJTrMc5Rk/e5ydh+t5t6FlxD8PXsjKIrK/qIa0hNCyT1Ww5WXpWBuPn9NoSSp98DF+gHuTySGvScx7D2J4fkhcey9C9lR7uJonCuEEEKIs5KkLoQQQgwQktSFEEKIAUKSuhBCCDFASFIXQgghBghJ6kIIIcQAIUldCCGEGCAkqQshhBADhCR1IYQQYoCQpC6EEEIMEJLUhRBCiAFCkroQQggxQEhSF0IIIQYISepCCCHEACFJXQghhBggJKkLIYQQA4QkdSGEEGKAkKQuhBBCDBAaVVXVvj4JIYQQQvSe3KkLIYQQA4QkdSGEEGKAkKQuhBBCDBCS1IUQQogBQpK6EEIIMUBIUhdCCCEGCH1fn0B/oCgKjz/+OPn5+Xh7e7Nq1SqSkpL6+rT6LbvdzqOPPorBYMBms3H33XeTlpbGihUr0Gg0pKen88c//hGtVsuLL77I5s2b0ev1PProo4waNaqvT79fqa2tZeHChbz22mvo9XqJ4Tl45ZVX2LhxI3a7ncWLFzNx4kSJYw/Y7XZWrFiBwWBAq9Xyl7/8RT6LPbB//35Wr17Nm2++SWlpabfj1tVze00V6tq1a9VHHnlEVVVV3bdvn7ps2bI+PqP+7cMPP1RXrVqlqqqq1tXVqTNnzlTvuusudceOHaqqqurKlSvVdevWqXl5eerSpUtVRVFUg8GgLly4sC9Pu9+x2Wzqr3/9a3Xu3LlqYWGhxPAc7NixQ73rrrtUp9Opmkwm9fnnn5c49tD69evV5cuXq6qqqtnZ2eq9994rMeymV199Vb3mmmvUm266SVVVtUdx6+y554MMvwM5OTlMnz4dgDFjxpCXl9fHZ9S/zZs3j/vuu8/9s06n49ChQ0ycOBGAGTNmsG3bNnJycpg2bRoajYa4uDicTid1dXV9ddr9zlNPPcXNN99MdHQ0gMTwHGRnZ5ORkcE999zDsmXLmDVrlsSxh1JSUnA6nSiKgslkQq/XSwy7KTExkRdeeMH9c0/i1tlzzwdJ6oDJZCIwMND9s06nw+Fw9OEZ9W8BAQEEBgZiMplYvnw5999/P6qqotFo3I83Nzd7xLXt9wI+/vhjwsPD3ReTgMTwHNTX15OXl8dzzz3Hn/70Jx5++GGJYw/5+/tjMBiYP38+K1euZOnSpRLDbrryyivR69tnsXsSt86eez7InDoQGBiI2Wx2/6woSof/KOGpqqqKe+65hyVLlrBgwQKeeeYZ92Nms5ng4GCPuJrNZoKCgvridPudjz76CI1Gw/bt2zly5AiPPPJIh7seiWH3hIaGkpqaire3N6mpqfj4+HDixAn34xLHs/vPf/7DtGnTeOihh6iqquLWW2/Fbre7H5cYdt/pc+Jni1tnzz0v53BejnKRGzduHFlZWQDk5uaSkZHRx2fUv9XU1HD77bfz29/+lhtvvBGAzMxMdu7cCUBWVhYTJkxg3LhxZGdnoygKlZWVKIpCeHh4X556v/H222/z1ltv8eabbzJ8+HCeeuopZsyYITHsofHjx7NlyxZUVeXkyZNYLBamTJkiceyB4OBgd3IOCQnB4XDI3/M56kncOnvu+SAbutBe/V5QUICqqjz55JMMGTKkr0+r31q1ahVff/01qamp7t899thjrFq1CrvdTmpqKqtWrUKn0/HCCy+QlZWFoij8/ve/P28f3IFk6dKlPP7442i1WlauXCkx7KGnn36anTt3oqoqDzzwAAkJCRLHHjCbzTz66KMYjUbsdju33HILI0eOlBh2U0VFBQ8++CBr1qyhuLi423Hr6rm9JUldCCGEGCBk+F0IIYQYICSpCyGEEAOEJHUhhBBigJCkLoQQQgwQktSFEEKIAUKSuhBCCDFASFIXQgghBghJ6kIIIcQA8f8BPwXfyHAY6bwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.style.use('seaborn')\n",
    "    \n",
    "def plotLosses(trainLoss,validationLoss):\n",
    "    plt.plot(trainLoss,label='Training MAE')\n",
    "    plt.plot(validationLoss,label='Validation MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotLosses(hist.history['mean_absolute_error'],hist.history['val_mean_absolute_error']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights file of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = 'CheckPoints/Weights-747--18510.35600.hdf5' # choose the best checkpoint \n",
    "model.load_weights(weights_file) # load it\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(Xt):\n",
    "    predictions=model.predict(Xt)\n",
    "    predictions={'Id':[i for i in range(1461,1461+Xt.shape[0])],'SalePrice':np.array(predictions).reshape(-1,)}\n",
    "    predictions=pd.DataFrame(predictions)\n",
    "    predictions.to_csv('KaggleHousingPredictions.csv',index=False)\n",
    "getPredictions(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
