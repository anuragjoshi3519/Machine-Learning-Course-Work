{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "#from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageData(path):\n",
    "    p = Path(path)\n",
    "    dirs= p.glob('*')\n",
    "\n",
    "    label_dict={'cat':0,'dog':1,'horse':2,'human':3}\n",
    "    labels=[]\n",
    "    image_data=[]\n",
    "    \n",
    "    for folder in dirs:\n",
    "        label = str(folder).split('/')[-1][:-1]\n",
    "        for img_path in folder.glob('*.jpg'):\n",
    "            img=cv2.imread(str(img_path))\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            img=cv2.resize(img,(40,40))\n",
    "\n",
    "            image_data.append(img)\n",
    "            labels.append(label_dict[label])\n",
    "\n",
    "    image_data=np.array(image_data)\n",
    "    labels=np.array(labels)\n",
    "\n",
    "    ## Random Shuffling of image_data and labels\n",
    "\n",
    "    image_with_label= list(zip(image_data,labels))  ## zip\n",
    "    random.shuffle(image_with_label)\n",
    "    image_data[:],labels[:]=zip(*image_with_label)  #unzip\n",
    "    \n",
    "    return image_data.reshape(image_data.shape[0],-1),labels,label_dict \n",
    "\n",
    "def generateClasswiseData(X,Y):\n",
    "    data={}\n",
    "    \n",
    "    no_of_classes=len(np.unique(Y))\n",
    "    no_of_samples=X.shape[0]\n",
    "    \n",
    "    for i in range(no_of_classes):\n",
    "        data[i]=[]\n",
    "        \n",
    "    for i in range(no_of_samples):\n",
    "        data[Y[i]].append(X[i])\n",
    "        \n",
    "    for k in range(no_of_classes):\n",
    "        data[k]=np.array(data[k])\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "## one-vs-one\n",
    "def getPairData(d1,d2):\n",
    "    \n",
    "    l1=d1.shape[0]\n",
    "    l2=d2.shape[0]\n",
    "    data=np.zeros((l1+l2,d1.shape[1]))\n",
    "    labels=np.zeros(l1+l2)\n",
    "    \n",
    "    data[:l1]=d1\n",
    "    data[l1:]=d2\n",
    "    \n",
    "    labels[:l1]=1\n",
    "    labels[l1:]=-1\n",
    "    \n",
    "    return data,labels\n",
    "\n",
    "def drawImg(img):\n",
    "    img=img.reshape(40,40,3)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C=1.0):\n",
    "        self.C=C\n",
    "        self.W_=0\n",
    "        self.b_=0\n",
    "        \n",
    "    def hingeLoss(self,X,Y,W,b):\n",
    "        loss=0.5*np.dot(W,W.T)\n",
    "        \n",
    "        m=X.shape[0]\n",
    "        \n",
    "        for i in range(m):\n",
    "            ti=Y[i]*(np.dot(W,X[i].T)+b)\n",
    "            loss+=self.C*max(0,1-ti)\n",
    "            \n",
    "        return loss[0][0]\n",
    "    \n",
    "    def fit(self,X,Y,batch_size=120,learning_rate=0.001,max_itr=400):\n",
    "        n=X.shape[1] # no. of features\n",
    "        m=X.shape[0] # no. of samplesimage_data,labels\n",
    "        \n",
    "        W=np.zeros((1,n))\n",
    "        b=0\n",
    "        \n",
    "        #training\n",
    "        losses=[]\n",
    "        \n",
    "        for _ in range(max_itr):\n",
    "            \n",
    "            l=self.hingeLoss(X,Y,W,b)\n",
    "            losses.append(l)\n",
    "            \n",
    "            #ids for mini batch\n",
    "            ids=np.arange(m)\n",
    "            np.random.shuffle(ids)\n",
    "             \n",
    "            #mini-batch gradient descent\n",
    "            for batch_start in range(0,m,batch_size):\n",
    "                gradw=0\n",
    "                gradb=0\n",
    "                for j in range(batch_start,batch_start+batch_size):\n",
    "                    if j<m:\n",
    "                        i=ids[j]\n",
    "                        ti=Y[i]*(np.dot(W,X[i].T)+b)\n",
    "\n",
    "                        if ti>1:\n",
    "                            gradw+=0\n",
    "                            gradb+=0\n",
    "                        else:\n",
    "                            gradw+=self.C*X[i]*Y[i]\n",
    "                            gradb+=self.C*Y[i]\n",
    "                \n",
    "                W= W - learning_rate*(W - gradw)\n",
    "                b= b + learning_rate*gradb\n",
    "            \n",
    "        self.W_=W\n",
    "        self.b_=b\n",
    "            \n",
    "        return self.W_,self.b_,losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,Y):\n",
    "    data=generateClasswiseData(X,Y)\n",
    "    svc=SVM()\n",
    "    svm_classifiers={}\n",
    "    for i in range(len(data)):\n",
    "        svm_classifiers[i]={}\n",
    "        for j in range(i+1,len(label_dict)):\n",
    "            x,y=getPairData(data[i],data[j])\n",
    "            wts,b,losses=svc.fit(x,y,learning_rate=0.0000001,max_itr=1000)\n",
    "            svm_classifiers[i][j]=(wts,b)\n",
    "            \n",
    "#             plt.plot(losses)\n",
    "#             plt.show()\n",
    "    return svm_classifiers        \n",
    "\n",
    "def predict(X,svm_classifiers):\n",
    "    X=X.reshape(-1,1)\n",
    "    classes=len(svm_classifiers)\n",
    "    count=np.zeros(classes,)\n",
    "    for i in range(classes):\n",
    "        for j in range(i+1,classes):\n",
    "            W = svm_classifiers[i][j][0]\n",
    "            b = svm_classifiers[i][j][1]\n",
    "            if (np.dot(W,X)+ b)>=0:\n",
    "                count[i]+=1\n",
    "            else:\n",
    "                count[j]+=1\n",
    "            \n",
    "    index=np.argmax(count)\n",
    "    return index\n",
    "\n",
    "def score(X,Y):\n",
    "    count=0\n",
    "    for i in range(X.shape[0]):\n",
    "        if Y[i]==predict(X[i],svm_classifiers):\n",
    "            count+=1\n",
    "        \n",
    "    return count/X.shape[0]\n",
    "# svc=svm.SVC(kernel='poly',gamma='auto')\n",
    "# svc.fit(image_data,image_labels)\n",
    "# svc.score(image_data,image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data,image_labels,label_dict= getImageData('images')\n",
    "svm_classifiers= train(image_data,image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6534653465346535\n"
     ]
    }
   ],
   "source": [
    "print(score(image_data,image_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection impfrom multiclassSVM import OneVsOneSVM\n",
    "svc=OneVsOneSVM()\n",
    "svc.fit(X,Y)\n",
    "svc.score(X,Y)ort GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.349009900990099\n"
     ]
    }
   ],
   "source": [
    "# params=[\n",
    "#     {\n",
    "#         'kernel': ['linear','rbf','poly','sigmoid'],\n",
    "#         'C':[0.1,1.0,2.0,5.0]\n",
    "#     }\n",
    "# ]\n",
    "# gs=GridSearchCV(estimator=svm.SVC(gamma='auto'),param_grid=params,cv=5,n_jobs=4,scoring='accuracy')\n",
    "# gs.fit(image_data,image_labels)\n",
    "# print(gs.best_estimator_)\n",
    "# print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6757425742574258\n"
     ]
    }
   ],
   "source": [
    "svc=svm.SVC(kernel='linear',C=1.0)\n",
    "svc.fit(image_data,image_labels)\n",
    "print(svc.score(image_data,image_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6150990099009901"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiclassSVM import OneVsOneSVM\n",
    "svc=OneVsOneSVM()\n",
    "svc.fit(image_data,image_labels)\n",
    "svc.score(image_data,image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
